#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{multicol} 
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\rightmargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Stability-Optimized High Strong Order Methods for Stochastic Differential
 Equations with Additive and Diagonal Noise
\end_layout

\begin_layout Author
Chris Rackauckas and Qing Nie
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Stochastic differential equations have seen increasing use in scientific
 fields such as biology and climate science due to their ability to capture
 the randomness inherent in physical systems.
 These equations are of the general form:
\begin_inset Formula 
\[
dX_{t}=f(t,X_{t})dt+g(t,X_{t})dW_{t}
\]

\end_inset

 where 
\begin_inset Formula $X_{t}$
\end_inset

 is a 
\begin_inset Formula $d$
\end_inset

-dimensional vector, where 
\begin_inset Formula $f:\mathbb{R}^{d}\rightarrow\mathbb{R}^{d}$
\end_inset

 is the drift coefficient and 
\begin_inset Formula $g:\mathbb{R}^{d}\rightarrow\mathbb{R}^{d\times m}$
\end_inset

 is a matrix equation known as the diffusion coefficient which describes
 the amount and mixtures of the noise process 
\begin_inset Formula $W_{t}$
\end_inset

 which is a 
\begin_inset Formula $m$
\end_inset

-dimensional Brownian motion.
 In many models, noise is added to deterministic equations phenomenologically.
 In one case, the noise process is modeled as exogenous to the system and
 thus not dependent the system itself, leading to the assumption that 
\begin_inset Formula $g(t,X_{t})\equiv g(t)$
\end_inset

.
 This case is known as additive noise.
 Another common case is multiplicative noise, where to each deterministic
 equation a noise term 
\begin_inset Formula $\sigma_{i}X_{t}^{i}dW_{t}$
\end_inset

 is added to give proportional noise.
 This results in 
\begin_inset Formula $g(t,X_{t})$
\end_inset

 being the diagonal matrix 
\begin_inset Formula $\left(\sigma_{i}X_{t}^{i}\right)$
\end_inset

 and thus falling into the category of diagonal noise.
 In contrast to how common models of this form occur, methods which utilize
 this functional form for increased efficiency are relatively underdeveloped.
\end_layout

\begin_layout Standard
The bread-and-butter methods for the integration of ordinary differential
 equations 
\begin_inset Formula 
\[
x'(t)=f(t,x)
\]

\end_inset

are adaptive Runge-Kutta methods.
 Runge first extended the Euler method to greater accuracy in 1895.
 Later, these methods were extended to a general form resulting in the theory
 of the Butcher tableau.
 In this framework, a Runge-Kutta method
\begin_inset Formula 
\begin{align*}
x_{n+1} & =x_{n}+h_{n}\sum_{j=1}^{s}b_{j}k_{j},\,\,\,\hat{x}_{n+1}=x_{n}+h_{n}\sum_{j=1}^{s}\hat{b}_{j}k_{j}\\
f_{j} & =f\left(x_{n}+c_{i}h_{n},y_{n}+h_{n}\sum_{j=1}^{s}a_{ij}k_{j}\right)
\end{align*}

\end_inset

is defined by a table of coefficients:
\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $c_{1}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $a_{11}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $a_{12}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\ldots$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $a_{1s}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $c_{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $a_{21}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $a_{22}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\ldots$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $a_{2s}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\vdots$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\vdots$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\vdots$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\vdots$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $c_{s}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $a_{s1}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $a_{s2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\ldots$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $a_{ss}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $b_{1}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $b_{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\ldots$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $b_{s}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $x_{n+1}$
\end_inset

 is the approximation to 
\begin_inset Formula $x(t_{j}+\Delta t)$
\end_inset

 where 
\begin_inset Formula $t_{j}$
\end_inset

 is the 
\begin_inset Formula $i$
\end_inset

th timepoint, and 
\begin_inset Formula $\hat{x}_{n+1}$
\end_inset

 is an embedded approximation of a different order.
 Using 
\begin_inset Formula $E_{n}=\Vert x_{n}-\hat{x}_{n}\Vert$
\end_inset

 as a local error estimator, the timestep is adaptive using the error estimate.
 One common algorithm for doing so is
\begin_inset Formula 
\[
h_{n+1}=0.9h_{n}\left(\frac{TOL}{E_{n}}\right)^{\frac{1}{p}}
\]

\end_inset

 due to optimality results by Cechino where 
\begin_inset Formula $TOL$
\end_inset

 is a user-chosen error tolerance and 
\begin_inset Formula $p$
\end_inset

 is the order of the method.
\end_layout

\begin_layout Standard
Early work in Runge-Kutta methods focused on the development of high order
 methods.
 Fehlberg developed the first 5th order method with an embedded error estimator.
 Dormand and Prince expanded the theory by considering the problem as a
 coefficient optimization problem: choosing coefficients for an order 4/5
 method which minimizes the the principle term in the truncation error to
 maximize the efficiency in each step, while controlling for an enlarged
 stability region.
 In order to make the problem tractable, they introduced extra assumptions
 and the resulting method, known as the RK5(4) or DP5 method (or through
 the name of its implementations dopri5 or ode45) is the standard method
 for integrating non-stiff ODEs.
 More recent work by Tsitouras used a minimal number of simplifying assumptions
 to generate a more efficient order 4/5 method.
 As an alternative to the mixed truncation error vs stability region selection,
 Verner derived methods with extended stability regions for higher orders.
\end_layout

\begin_layout Standard
An approach to the integration of stochastic differential equations is the
 use of adaptive Stochastic Runge-Kutta (SRK) methods.
 Kloden and Platen developed a theory of stochastic Taylor expansions which
 allowed the development of high strong order (greater than order 1.0) methods
 which replace the derivatives by approximations, also known as derivative-free
 or SRK methods.
 Burrage and Burrage introduced the use of colored trees for calculating
 the strong order conditions for SRK methods and thus extended the Butcher
 tableau theory to SDE with Stratonovich noise.
 Later work by Rossler extended the approach to Ito SDEs and along with
 relaxed conditions for commutative, scalar, diagonal, and additive noise.
 Rackauckas and Nie derived an extension to the Rossler methods which provides
 a natural embedded order 1.0 method and results in efficient adaptive timesteppi
ng for any Rossler method.
 However, to the author's knowledge, no attempts have been made at deriving
 optimal sets of coefficients for the high strong order adaptive SRK methods.
 
\end_layout

\begin_layout Standard
In this paper we develop a method for deriving optimal-stability SRK methods.
 Section 2 recaps the theory of high strong order SRK methods and their
 adaptive extensions.
 In Section 3 we derive a optimization problem whose solution is a stability-opt
imized SRK methods.
 Also discussed are extended constraints which are required for the stability
 and locality of the error estimator.
 In Section 4 we describe the numerical used to solve the optimization problem
 and the resulting explicit SRK methods.
 In Section 5 demonstrate the efficiency of our new methods on a set of
 test problems.
 We end by discussing the extension of our method of derivation to implicit
 and non-diagonal SRK methods.
\end_layout

\begin_layout Section
Adaptive Strong Order 1.0/1.5 Methods
\end_layout

\begin_layout Standard
Rosseler used a colored root tree analysis to developed order conditions
 for high order SRK methods.
 The diagonal noise methods utilize the same general form and order conditions
 as the methods for scalar noise so we use their notation for simplicity.
 The strong order 1.5 methods for scalar noise are of the form
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
X_{n+1}=X_{n}+\sum_{i=1}^{s}\alpha_{i}f\left(t_{n}+c_{i}^{(0)}h,H_{i}^{(0)}\right)+\sum_{i=1}^{s}\left(\beta_{i}^{(1)}I_{(1)}+\beta_{i}^{(2)}\frac{I_{(1,1)}}{\sqrt{h}}+\beta_{i}^{(3)}\frac{I_{(1,0)}}{h}+\beta_{i}^{(4)}\frac{I_{(1,1,1)}}{h}\right)g\left(t_{n}+c_{i}^{(1)}h\right)
\]

\end_inset

 with stages
\begin_inset Formula 
\begin{align*}
H_{i}^{(0)} & =X_{n}+\sum_{j=1}^{s}A_{ij}^{(0)}f\left(t_{n}+c_{j}^{(0)}h,H_{j}^{(0)}\right)h+\sum_{j=1}^{s}B_{ij}^{(0)}g\left(t_{n}+c_{j}^{(1)}h,H_{j}^{(1)}\right)\frac{I_{(1,0)}}{h}\\
H_{i}^{(1)} & =X_{n}+\sum_{j=1}^{s}A_{ij}^{(1)}f\left(t_{n}+c_{j}^{(0)}h,H_{j}^{(0)}\right)h+\sum_{j=1}^{s}B_{ij}^{(1)}g\left(t_{n}+c_{j}^{(1)}h,H_{j}^{(1)}\right)\sqrt{h}
\end{align*}

\end_inset

 where the 
\begin_inset Formula $I_{j}$
\end_inset

 are the Wiktorsson approximations to the iterated stochastic integrals.
 In the case of additive noise, this reduces to the form
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
X_{n+1}=X_{n}+\sum_{i=1}^{s}\alpha_{i}f\left(t_{n}+c_{i}^{(0)}h,H_{i}^{(0)}\right)+\sum_{i=1}^{s}\left(\beta_{i}^{(1)}I_{(1)}+\beta_{i}^{(2)}\frac{I_{(1,0)}}{h}\right)g\left(t_{n}+c_{i}^{(1)}h\right)
\]

\end_inset

 with stages
\begin_inset Formula 
\[
H_{i}^{(0)}=X_{n}+\sum_{j=1}^{s}A_{ij}^{(0)}f\left(t_{n}+c_{j}^{(0)}h,H_{j}^{(0)}\right)h+\sum_{j=1}^{s}B_{ij}^{(0)}g\left(t_{n}+c_{j}^{(1)}h\right)\frac{I_{(1,0)}}{h}.
\]

\end_inset

 The tuple of coefficients 
\begin_inset Formula $\left(A^{(j)},B^{(j)},\beta^{(j)},\alpha\right)$
\end_inset

 thus fully determine the SRK method.
 These coefficients are subject to the constraint equations:
\end_layout

\begin_layout Standard
The coefficients 
\begin_inset Newline newline
\end_inset


\begin_inset Formula $\left(A_{0},B_{0},\beta^{(i)},\alpha\right)$
\end_inset

 must satisfy the following order conditions to achieve order .5:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{multicols}{3}
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\alpha^{T}e=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(1)^{T}}e=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(2)^{T}}e=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(3)^{T}}e=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(4)^{T}}e=0$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{multicols}
\end_layout

\end_inset

 additionally, for order 1:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{multicols}{2}
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(1)^{T}}B^{(1)}e=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(2)^{T}}B^{(1)}e=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(3)^{T}}B^{(1)}e=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(4)^{T}}B^{(1)}e=0$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{multicols}
\end_layout

\end_inset

 and lastly for order 1.5:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{multicols}{2}
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\alpha^{T}A^{(0)}e=\frac{1}{2}$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\alpha^{T}B^{(0)}e=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\alpha^{T}\left(B^{(0)}e\right)^{2}=\frac{3}{2}$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(1)^{T}}A^{(1)}e=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(2)^{T}}A^{(1)}e=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(3)^{T}}A^{(1)}e=-1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(4)^{T}}A^{(1)}e=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(1)^{T}}\left(B^{(1)}e\right)^{2}=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(2)^{T}}\left(B^{(1)}e\right)^{2}=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(3)^{T}}\left(B^{(1)}e\right)^{2}=-1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(4)^{T}}\left(B^{(1)}e\right)^{2}=2$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(1)^{T}}\left(B^{(1)}\left(B^{(1)}e\right)\right)=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(2)^{T}}\left(B^{(1)}\left(B^{(1)}e\right)\right)=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(3)^{T}}\left(B^{(1)}\left(B^{(1)}e\right)\right)=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(4)^{T}}\left(B^{(1)}\left(B^{(1)}e\right)\right)=1$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{multicols}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
16.\thinspace\thinspace\thinspace\frac{1}{2}\beta^{(1)^{T}}\left(A^{(1)}\left(B^{(0)}e\right)\right)+\frac{1}{3}\beta^{(3)^{T}}\left(A^{(1)}\left(B^{(0)}e\right)\right)=0
\]

\end_inset

where 
\begin_inset Formula $f,g\in C^{1,2}(\mathcal{I}\times\mathbb{R}^{d},\mathbb{R}^{d})$
\end_inset

, 
\begin_inset Formula $c^{(i)}=A^{(i)}e$
\end_inset

, 
\begin_inset Formula $e=(1,1,1,1)^{T}$
\end_inset

.
 The reduced constraints for additive noise were derived for order 1:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{multicols}{3}
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\alpha^{T}e=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(1)^{T}}e=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(2)^{T}}e=0$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{multicols}
\end_layout

\end_inset

 and the additional conditions for order 1.5:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{multicols}{3}
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\alpha^{T}B^{(0)}e=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\alpha^{T}A^{(0)}e=\frac{1}{2}$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\alpha^{T}\left(B^{(0)}e\right)^{2}=\frac{3}{2}$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(1)^{T}}c^{(1)}=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(2)^{T}}c^{(1)}=-1$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{multicols}
\end_layout

\end_inset

where 
\begin_inset Formula $c^{(0)}=A^{(0)}e$
\end_inset

 with 
\begin_inset Formula $f\in C^{1,3}(\mathcal{I}\times\mathbb{R}^{d},\mathbb{R}^{d})$
\end_inset

 and 
\begin_inset Formula $g\in C^{1}(\mathcal{I},\mathbb{R}^{d})$
\end_inset

.
\end_layout

\begin_layout Standard
Rackauckas and Nie showed that for any method of this form, there exists
 an error estimator
\begin_inset Formula 
\[
E=\delta E_{D}+E_{N}
\]

\end_inset

 where 
\begin_inset Formula $E_{D}$
\end_inset

 is the deterministic (drift) error estimator and 
\begin_inset Formula $E_{N}$
\end_inset

 is the noise error estimator, given respectively by
\begin_inset Formula 
\begin{align*}
E_{D} & =\left|h\sum_{i\in I_{1}}\left(-1\right)^{\sigma(i)}f\left(t_{n}+c_{i}^{(0)}h,H_{i}^{(0)}\right)\right|\\
E_{N} & =\left|\sum_{i\in I_{1}}\left(\beta_{i}^{(3)}\frac{I_{(1,0)}}{h}+\beta_{i}^{(4)}\frac{I_{(1,1,1)}}{h}\right)g\left(t_{n}+c_{i}^{(1)}h,H_{i}^{(1)}\right)\right|
\end{align*}

\end_inset

with some constraints on 
\begin_inset Formula $\sigma(i)$
\end_inset

 and the 
\begin_inset Formula $I_{j}$
\end_inset

.
 Thus unlike in the theory of ordinary differential equations, the choice
 of coefficients for SRK methods does not require explicitly finding an
 embedded method.
\end_layout

\begin_layout Section
Optimized-Stability High Order SRK Methods with Additive Noise
\end_layout

\begin_layout Standard
Using the terms as defined by Kloden and Platen, we define a discrete approximat
ion as numerically stable if for any finite time interval 
\begin_inset Formula $\left[t_{0},T\right]$
\end_inset

, there exists a positive constant 
\begin_inset Formula $\Delta_{0}$
\end_inset

 such that for each 
\begin_inset Formula $\epsilon>0$
\end_inset

 and each 
\begin_inset Formula $\delta\in\left(0,\Delta_{0}\right)$
\end_inset

 
\begin_inset Formula 
\[
\lim_{\left|X_{0}^{\delta}-\bar{X}_{0}^{\delta}\right|\rightarrow0}\sup_{t_{0}\leq t\leq T}P\left(\left|X_{t}^{\delta}-\bar{X}_{t}^{\delta}\right|\geq\epsilon\right)=0
\]

\end_inset

 where 
\begin_inset Formula $X_{n}^{\delta}$
\end_inset

 is a discrete time approximation with maximum step size 
\begin_inset Formula $\delta>0$
\end_inset

 starting at 
\begin_inset Formula $X_{0}^{\delta}$
\end_inset

 and 
\begin_inset Formula $\bar{X}_{n}^{\delta}$
\end_inset

 respectively starting at 
\begin_inset Formula $\bar{X}_{n}^{\delta}$
\end_inset

.
 For additive noise, we consider the complex-valued linear test equations
\begin_inset Formula 
\[
dX_{t}=\mu X_{t}dt+dW_{t}
\]

\end_inset

 where 
\begin_inset Formula $\lambda$
\end_inset

 is a complex number.
 In this framework, a scheme which can be written in the form 
\begin_inset Formula 
\[
X_{n+1}^{h}=X_{n}^{h}G\left(\mu h\right)+Z_{n}^{\delta}
\]

\end_inset

with a constant step size 
\begin_inset Formula $\delta\equiv h$
\end_inset

 and 
\begin_inset Formula $Z_{n}^{\delta}$
\end_inset

 are random variables which do not depend on the 
\begin_inset Formula $Y_{n}^{\delta}$
\end_inset

, then the region of absolute stability is the set where for 
\begin_inset Formula $z=\mu h$
\end_inset

, 
\begin_inset Formula $\left|G(z)\right|<1$
\end_inset

.
 
\end_layout

\begin_layout Standard
The additive SRK method can be written as
\begin_inset Formula 
\[
X_{n+1}^{h}=X_{n}^{h}+z\left(\alpha\cdot H^{(0)}\right)+\beta^{(1)}\sigma I_{(1)}+\sigma\beta^{(2)}\frac{I_{(1,0)}}{h}
\]

\end_inset

 where
\begin_inset Formula 
\[
H^{(0)}=\left(I-zA^{(0)}\right)^{-1}\left(\hat{X_{n}^{h}}+B^{(0)}e\sigma\frac{I_{(1,0)}}{h}\right)
\]

\end_inset

where 
\begin_inset Formula $\hat{X_{n}^{h}}$
\end_inset

 is the size 
\begin_inset Formula $s$
\end_inset

 constant vector of elements 
\begin_inset Formula $X_{n}^{h}$
\end_inset

 and 
\begin_inset Formula $e=\left(1,1,1,1\right)^{T}$
\end_inset

.
 By substitution we receive
\begin_inset Formula 
\[
X_{n+1}^{h}=X_{n}^{h}\left(1+z\left(\alpha\cdot\left(I-zA^{(0)}\right)^{-1}\right)\right)+\left(I-zA^{(0)}\right)^{-1}B^{(0)}e\sigma\frac{I_{(1,0)}}{h}+\beta^{(1)}\sigma I_{(1)}+\sigma\beta^{(2)}\frac{I_{(1,0)}}{h}
\]

\end_inset

This set of equations decouples to the form of Equation ## since the iterated
 stochastic integral approximation 
\begin_inset Formula $I_{j}$
\end_inset

 are random numbers and are independent of the 
\begin_inset Formula $X_{n}^{h}$
\end_inset

.
 Thus the stability condition is determined by the equation
\begin_inset Formula 
\[
G(z)=1+z\left(\alpha\cdot\left(I-zA^{(0)}\right)^{-1}\right).
\]

\end_inset


\end_layout

\begin_layout Subsection
Stability-Optimal Explicit Methods
\end_layout

\begin_layout Standard
For explicit methods, the 
\begin_inset Formula $A^{(i)}$
\end_inset

 and 
\begin_inset Formula $B^{(i)}$
\end_inset

 are lower diagonal and we receive the simplified stability function 
\begin_inset Formula 
\[
G(z)=1+A_{21}z^{2}\alpha_{2}+z\left(\alpha_{1}+\alpha_{2}\right)
\]

\end_inset

 for a two-stage additive noise SRK method.
 For this method we will find the method which optimizes the stability in
 the real part of 
\begin_inset Formula $z$
\end_inset

.
 Thus we wish to find 
\begin_inset Formula $A^{(0)},\alpha$
\end_inset

 s.t.
 the negative real roots of 
\begin_inset Formula $\left|G(z)\right|=1$
\end_inset

 are minimized.
 By the quadratic equation we see that there exists only a single negative
 root: 
\begin_inset Formula $z=\frac{1-\sqrt{1+8\alpha_{2}}}{2\alpha_{2}}$
\end_inset

.
 Using Mathematica's minimum function, we determine that the minimum value
 for this root subject to the order constraints is 
\begin_inset Formula $z=\frac{3}{4}\left(1-\sqrt{\frac{19}{3}}\right)\approx-1.13746$
\end_inset

.
 We see that this is achieved when 
\begin_inset Formula $\alpha=\frac{2}{3}$
\end_inset

, meaning that the SRA1 method due to Rossler achieves the maximum stability
 criteria.
 However, given extra degrees of freedom, we impose that 
\begin_inset Formula $c_{1}^{(0)}=c_{1}^{(1)}=0$
\end_inset

 and 
\begin_inset Formula $c_{2}^{(0)}=c_{2}^{(1)}=1$
\end_inset

 so that the error estimator spans the whole interval.
 This can lead to improved robustness of the adaptivity.
 Under these conditions we find the solution
\begin_inset Formula 
\begin{align*}
A^{(0)} & =\left(\begin{array}{cc}
0 & 0\\
\frac{3}{4} & 0
\end{array}\right),\thinspace\thinspace\thinspace B^{(0)}=\left(\begin{array}{cc}
0 & 0\\
\frac{3}{2} & 0
\end{array}\right),\thinspace\thinspace\thinspace\thinspace\alpha=\left(\begin{array}{c}
\frac{1}{3}\\
\frac{2}{3}
\end{array}\right)\\
\beta^{(1)} & =\left(\begin{array}{c}
0\\
1
\end{array}\right),\thinspace\thinspace\thinspace\beta^{(2)}=\left(\begin{array}{c}
1\\
-1
\end{array}\right),\thinspace\thinspace\thinspace c^{(0)}=\left(\begin{array}{c}
0\\
1
\end{array}\right),\,\,\,c^{(1)}=\left(\begin{array}{c}
0\\
1
\end{array}\right)
\end{align*}

\end_inset

 is the unique set of coefficients which satisfies these constraints, and
 achieves the optimal value for the root.
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename C:/Users/Chris/.julia/v0.5/SRKGenerator/assets/obj_poly_solve/2stage_additive.pdf
	scale 25

\end_inset


\end_layout

\begin_layout Subsection
An A-Stable L-Stable Implicit Method For Stiff SDEs with Additive Noise
\end_layout

\begin_layout Standard
It's clear that, as in the case for deterministic equations, the explicit
 methods cannot be made A-stable.
 However, the implicit two-stage additive noise SRK method is determined
 by
\begin_inset Formula 
\[
G(z)=\frac{z(A_{11}(A_{22}z-\alpha_{2}z-1)+A_{12}z(\alpha_{1}-A_{21})+A_{21}\ensuremath{\alpha_{2}}z-A_{22}(\alpha_{1}z+1)+\alpha_{1}+\alpha_{2})+1}{A_{11}z(A_{22}z-1)-z(A_{12}A_{21}z+A_{22})+1}
\]

\end_inset

 which is 
\begin_inset Formula $A$
\end_inset

-stable if 
\begin_inset Formula 
\[
A_{11}z(A_{22}z-1)-z(A_{12}A_{21}z+A_{22})+1>z(A_{11}(A_{22}z-\alpha_{2}z-1)+A_{12}z(\alpha_{1}-A_{21})+A_{21}\ensuremath{\alpha_{2}}z-A_{22}(\alpha_{1}z+1)+\alpha_{1}+\alpha_{2})+1.
\]

\end_inset

 Notice that the numerator equals the denominator if and only if 
\begin_inset Formula $z=0$
\end_inset

 or
\begin_inset Formula 
\[
z=\frac{\alpha_{1}+\alpha_{2}}{\left(A_{22}-A_{12}\right)\alpha_{1}+\left(A_{11}-A_{21}\right)\alpha_{2}}.
\]

\end_inset

 From the order conditions we know that 
\begin_inset Formula $\alpha_{1}+\alpha_{2}=1$
\end_inset

 which means that no root exists with 
\begin_inset Formula $Re(z)<0$
\end_inset

 if 
\begin_inset Formula $\left(A_{22}-A_{12}\right)\alpha_{1}+\left(A_{11}-A_{21}\right)\alpha_{2}>0$
\end_inset

.
 Thus under these no roots conditions, we can determine A-stability by checking
 the inequality at 
\begin_inset Formula $z=1$
\end_inset

, which gives 
\begin_inset Formula $1>\left(A_{22}-A_{12}\right)\alpha_{1}+\left(A_{11}-A_{21}\right)\alpha_{2}$
\end_inset

.
 Using the order condition, we have a total of four constraints on the 
\begin_inset Formula $A^{(0)}$
\end_inset

 and 
\begin_inset Formula $\alpha$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\left(A_{11}+A_{12}\right)\alpha_{1}+\left(A_{21}+A_{22}\right)\alpha_{2} & =\frac{1}{2}\\
\alpha_{1}+\alpha_{2} & =1\\
0<\left(A_{22}-A_{12}\right)\alpha_{1}+\left(A_{11}-A_{21}\right)\alpha_{2} & <1
\end{align*}

\end_inset

An immediate fact we note is that none of the 2-stage (Order 3) Labatto
 or Radau methods create stochastically A-stable methods.
 Instead, we wish to derive methods which have similar properties and have
 stochastic A-stability.
 One property we extend is L-stability.
 The straightforward extension of L-stability is the condition
\begin_inset Formula 
\[
\lim_{z\rightarrow\infty}G(z)=0.
\]

\end_inset

This implies that
\begin_inset Formula 
\[
\frac{-A_{11}A_{22}+A_{11}\alpha_{2}+A_{12}A_{21}-A_{12}\alpha_{1}-A_{21}\alpha_{2}+A_{22}\alpha_{2}\alpha_{1}}{A_{12}A_{21}-A_{11}A_{22}}=0
\]

\end_inset

 The denominator is 
\begin_inset Formula $-\det(A^{(0)})$
\end_inset

 which implies 
\begin_inset Formula $A^{(0)}$
\end_inset

 must be non-singular.
 Next, we attempt to impose B-stability on the drift portion of the method.
 We use the condition due to Burrage and Butcher that for 
\begin_inset Formula $B=\text{diag}\left(\alpha_{1},\alpha_{2}\right)$
\end_inset

 
\begin_inset Formula $M=BA^{(0)}+A^{(0)}B-\alpha\alpha^{T}$
\end_inset

, we require both 
\begin_inset Formula $B$
\end_inset

 and 
\begin_inset Formula $M$
\end_inset

 to be non-negative definite.
 However, in the supplemental Mathematica notebooks we show computationally
 that there is no 2-stage SRK method of this form which satisfies all three
 of these stability conditions.
 Thus we settle for A-stability and L-stability.
\end_layout

\begin_layout Standard
Recalling that 
\begin_inset Formula $c^{(0)}$
\end_inset

 and 
\begin_inset Formula $c^{(1)}$
\end_inset

 are the locations in time where 
\begin_inset Formula $f$
\end_inset

 and 
\begin_inset Formula $g$
\end_inset

 are approximated respectively, we wish to impose
\begin_inset Formula 
\begin{align*}
c_{2}^{(0)} & =1\\
c_{2}^{(1)} & =1
\end{align*}

\end_inset

 so that the error estimator covers the entire interval of integration (for
 robustness to discontinuities).
 Since 
\begin_inset Formula $c^{(0)}=A^{(0)}e$
\end_inset

, this leads to the condition 
\begin_inset Formula $A_{21}+A_{22}=1$
\end_inset

.
 Using the constraint-satisfaction algorithm FindInstance in Mathematica,
 we find the following coefficient set:
\begin_inset Formula 
\begin{align*}
A^{(0)} & =\left(\begin{array}{cc}
2 & -\frac{7}{2}\\
0 & \frac{3}{2}
\end{array}\right),\thinspace\thinspace\thinspace B^{(0)}=\left(\begin{array}{cc}
0 & 0\\
\frac{3}{2} & 0
\end{array}\right),\thinspace\thinspace\thinspace\thinspace\alpha=\left(\begin{array}{c}
\frac{1}{3}\\
\frac{2}{3}
\end{array}\right)\\
\beta^{(1)} & =\left(\begin{array}{c}
0\\
1
\end{array}\right),\thinspace\thinspace\thinspace\beta^{(2)}=\left(\begin{array}{c}
1\\
-1
\end{array}\right),\thinspace\thinspace\thinspace c^{(0)}=\left(\begin{array}{c}
0\\
1
\end{array}\right),\,\,\,c^{(1)}=\left(\begin{array}{c}
0\\
1
\end{array}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Section
Optimized-Stability Order 1.5 SRK Methods with Diagonal Noise
\end_layout

\begin_layout Subsection
A Multivariate Lamperti Transform for Multiplicative Noise to Additive SRK
\end_layout

\begin_layout Standard
Given the efficiency of the methods for additive noise, one method for developin
g efficient methods for more general noise processes is to use a transform
 of diagonal noise processes to additive noise.
 This transform is due to Lamperti, which states that the SDE of the form
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
dX_{t}=f(t,X_{t})dt+\sigma(t,X_{t})R(t)dW_{t}
\]

\end_inset

 where 
\begin_inset Formula $\sigma$
\end_inset

 a diagonal matrix with diagonal elements 
\begin_inset Formula $\sigma_{i}(t,X_{i,t})$
\end_inset

 has the transformation
\begin_inset Formula 
\[
Z_{i,t}=\psi_{i}(t,X_{i,t})=\int\frac{1}{\sigma_{i}(x,t)}dx\mid_{x=X_{i,t}}
\]

\end_inset

which will result in an Ito process with the ith element given by
\begin_inset Formula 
\[
dZ_{i,t}=\left(\frac{\partial}{\partial t}\psi_{i}(t,x)\mid_{x=\psi^{-1}(t,Z_{i,t})}+\frac{f_{i}(\psi^{-1}(t,Z_{t}),t)}{\frac{1}{2}\frac{\partial}{\partial x}\sigma_{i}\left(\psi_{i}^{-1}\left(t,Z_{i,t}\right)\right)}\right)dt+\sum_{j=1}^{n}r_{ij}(t)dw_{j,t}
\]

\end_inset

 with
\begin_inset Formula 
\[
X_{t}=\psi^{-1}\left(t,Z_{t}\right).
\]

\end_inset

 This is easily verified using Ito's Lemma.
 An example of such a transformation is multidimensional geometric Brownian
 motion, where 
\begin_inset Formula $A=diag(a_{1},a_{2})$
\end_inset

, 
\begin_inset Formula $\sigma=diag(X_{1},X_{2})$
\end_inset

, and 
\begin_inset Formula $R=r_{ij}$
\end_inset

.
 Then in this case, 
\begin_inset Formula $Z=\psi(X)=\log(X)$
\end_inset

 and
\begin_inset Formula 
\[
d\left[\begin{array}{c}
Z_{1}\\
Z_{2}
\end{array}\right]=\left[\begin{array}{c}
a_{1}-\frac{1}{2}\left(r_{11}^{2}+r_{12}^{2}\right)\\
a_{2}-\frac{1}{2}\left(r_{21}^{2}+r_{22}^{2}\right)
\end{array}\right]dt+\left[\begin{array}{cc}
r_{11} & r_{12}\\
r_{21} & r_{22}
\end{array}\right]dW_{t}.
\]

\end_inset

 This transformation requires that 
\begin_inset Formula $\sigma_{i}^{-1}(t,X_{i,t})$
\end_inset

 is one-to-one, and thus does not exist in general for diagonal noise.
 However, in the case of mixed multiplicative and additive noise: 
\begin_inset Formula 
\[
dX_{t}=f(t,X_{t})dt+\sigma X_{t}dW_{t}
\]

\end_inset

 where 
\begin_inset Formula $\sigma$
\end_inset

 is a constant diagonal matrix, then
\begin_inset Formula 
\begin{align*}
d\log X_{t} & =\tilde{f}(t,X_{t})dt+dW_{t}\\
\tilde{f}(t,X_{t}) & =\frac{f(t,X_{t})}{\sigma X_{t}}
\end{align*}

\end_inset

 where the division is considered element-wise.
 Thus we can modify the additive SRK method to be in the form
\begin_inset Formula 
\[
\log X_{n+1}=\log X_{n}+\sum_{i=1}^{s}\alpha_{i}\tilde{f}\left(t_{n}+c_{i}^{(0)}h,\exp\left(H_{i}^{(0)}\right)\right)+\sum_{i=1}^{s}\left(\beta_{i}^{(1)}I_{(1)}+\beta_{i}^{(2)}\frac{I_{(1,0)}}{h}\right)
\]

\end_inset

with stages
\begin_inset Formula 
\[
H_{i}^{(0)}=\log X_{n}+\sum_{j=1}^{s}A_{ij}^{(0)}\tilde{f}\left(t_{n}+c_{j}^{(0)}h,\exp\left(H_{j}^{(0)}\right)\right)h+\sum_{j=1}^{s}B_{ij}^{(0)}\frac{I_{(1,0)}}{h}.
\]

\end_inset

 Back-transforming this, we get
\begin_inset Formula 
\[
X_{n+1}=X_{n}\exp\left(\sum_{i=1}^{s}\alpha_{i}\tilde{f}\left(t_{n}+c_{i}^{(0)}h,\exp\left(H_{i}^{(0)}\right)\right)+\sum_{i=1}^{s}\left(\beta_{i}^{(1)}I_{(1)}+\beta_{i}^{(2)}\frac{I_{(1,0)}}{h}\right)\right)
\]

\end_inset

 where the exponentiation is interpreted element-wise.
\end_layout

\begin_layout Subsection
The Stability Equation for Order 1.5 SRK Methods with Diagonal Noise
\end_layout

\begin_layout Standard
For diagonal noise, we will use the mean-square definition of stability.
 A method is mean-square stable if 
\begin_inset Formula $\lim_{n\rightarrow\infty}\mathbb{E}\left(\left|X_{n}\right|^{2}\right)=0$
\end_inset

 on the test equation
\begin_inset Formula 
\[
dX_{t}=\mu X_{t}dt+\sigma X_{t}dW_{t}.
\]

\end_inset

In matrix form we can re-write our method as given by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
X_{n+1}=X_{n}+\mu h\left(\alpha\cdot H^{(0)}\right)+\sigma I_{(1)}\left(\beta^{(1)}\cdot H^{(1)}\right)+\sigma\frac{I_{(1,1)}}{\sqrt{h}}\left(\beta^{(2)}\cdot H^{(1)}\right)+\sigma\frac{I_{(1,0)}}{h}\left(\beta^{(3)}\cdot H^{(1)}\right)+\sigma\frac{I_{(1,1,1)}}{h}\left(\beta^{(4)}\cdot H^{(1)}\right)
\]

\end_inset

 with stages
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
H^{(0)} & = & X_{n}+\mu\Delta tA^{(0)}H^{(0)}+\sigma\frac{I_{(1,0)}}{h}B^{(0)}H^{(1)},\\
H^{(1)} & = & X_{n}+\mu\Delta tA^{(1)}H^{(0)}+\sigma\sqrt{\Delta t}B^{(1)}H^{(1)}
\end{eqnarray*}

\end_inset

where 
\begin_inset Formula $\hat{X_{n}}$
\end_inset

 is the size 
\begin_inset Formula $s$
\end_inset

 constant vector of 
\begin_inset Formula $X_{n}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
H^{(0)} & = & \left(I-hA^{(0)}\right)^{-1}\left(\hat{X_{n}}+\sigma\frac{I_{(1,0)}}{h}B^{(0)}H^{(1)}\right),\\
H^{(1)} & = & \left(I-\sigma\sqrt{h}B^{(1)}\right)^{-1}\left(\hat{X_{n}}+\mu hA^{(1)}H^{(0)}\right)
\end{eqnarray*}

\end_inset

By the derivation in the appendix, we receive the equation
\end_layout

\begin_layout Standard

\size tiny
\begin_inset Formula 
\begin{eqnarray*}
S=E\left[\frac{U_{n+1}^{2}}{U_{n}^{2}}\right] & = & \{1+\mu ht\left(\alpha\cdot\left[\left(I-\mu\Delta tA^{(0)}-\mu\sigma I_{(1,0)}A^{(1)}B^{(0)}\left(I-\sigma\sqrt{h}B^{(1)}\right)^{-1}\right)^{-1}\left(I+\sigma\frac{I_{(1,0)}}{h}B^{(0)}\left(I-\sigma\sqrt{h}B^{(1)}\right)^{-1}\right)\right]\right)\\
 &  & +\sigma I_{(1)}\left(\beta^{(1)}\cdot\left[\left(I-\sigma\sqrt{h}B^{(1)}-\mu hA^{(1)}\left(I-\mu hA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{h}B^{(0)}\right)^{-1}\left(I+\mu hA^{(1)}\left(I-\mu hA^{(0)}\right)^{-1}\right)\right]\right)\\
 &  & +\sigma\frac{I_{(1,1)}}{\sqrt{h}}\left(\beta^{(2)}\cdot\left[\left(I-\sigma\sqrt{h}B^{(1)}-\mu hA^{(1)}\left(I-\mu hA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{h}B^{(0)}\right)^{-1}\left(I+\mu hA^{(1)}\left(I-\mu hA^{(0)}\right)^{-1}\right)\right]\right)\\
 &  & +\sigma\frac{I_{(1,0)}}{h}\left(\beta^{(3)}\cdot\left[\left(I-\sigma\sqrt{h}B^{(1)}-\mu hA^{(1)}\left(I-\mu hA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{h}B^{(0)}\right)^{-1}\left(I+\mu hA^{(1)}\left(I-\mu hA^{(0)}\right)^{-1}\right)\right]\right)\\
 &  & +\sigma\frac{I_{(1,1,1)}}{h}\left(\beta^{(4)}\cdot\left[\left(I-\sigma\sqrt{h}B^{(1)}-\mu hA^{(1)}\left(I-\mu hA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{h}B^{(0)}\right)^{-1}\left(I+\mu hA^{(1)}\left(I-\mu hA^{(0)}\right)^{-1}\right)\right]\right)\}^{2}
\end{eqnarray*}

\end_inset


\size default
We apply the substitutions from the Appendix and let
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
z & =\mu h,\\
w & =\sigma\sqrt{h}.
\end{align*}

\end_inset

In this space, 
\begin_inset Formula $z$
\end_inset

 is the stability variable for the drift term and 
\begin_inset Formula $w$
\end_inset

 is the stability in the diffusion term.
 Under this scaling 
\begin_inset Formula $\left(h,\sqrt{h}\right)$
\end_inset

, the equation becomes independent of 
\begin_inset Formula $h$
\end_inset

 and thus becomes a function 
\begin_inset Formula $S(z,w)$
\end_inset

 on the coefficients of the SRK method.
 The equation 
\begin_inset Formula $S(z,w)$
\end_inset

 in terms of its coefficients for explicit methods (
\begin_inset Formula $A^{(i)}$
\end_inset

 and 
\begin_inset Formula $B^{(i)}$
\end_inset

 lower diagonal) has millions of terms and is shown in the supplemental
 Mathematica notebook.
 Determination of the stability equation for the implicit methods was found
 to be computationally intractable and is an avenue for further research.
\end_layout

\begin_layout Subsection
An Optimization Problem for Determination of Coefficients
\end_layout

\begin_layout Standard
We wish to determine the coefficients for the additive and diagonal SRK
 methods which optimize the stability.
 To do so, we generate an optimization problem which we can numerically
 solve for the coefficients.
 To simplify the problem, we let 
\begin_inset Formula $z,w\in\mathbb{R}$
\end_inset

.
 Define the function
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
f\left(z,w;N,M\right)=\int_{-M}^{M}\int_{-N}^{1}\chi_{S(z,w)\leq1}(z,w)dzdw.
\]

\end_inset

Notice that for 
\begin_inset Formula $N,M\rightarrow\infty$
\end_inset

, 
\begin_inset Formula $f$
\end_inset

 is the area of the stability region.
 Thus we define the stability-optimized diagonal SRK method as the set of
 coefficients which achieves
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\max_{A^{(i)},B^{(i)},\beta^{(i)},\alpha} & f(z,w)\\
\text{subject to: } & \text{Order Constraints}
\end{align*}

\end_inset

 However, like with the SRK methods for additive noise, we impose a few
 extra constraints to add robustness to the error estimator.
 In all cases we impose 
\begin_inset Formula $0<c_{i}^{(0)},c_{i}^{(1)}<1$
\end_inset

 .
 Additionally we can prescribe 
\begin_inset Formula $c_{4}^{(0)}=c_{4}^{(1)}=1$
\end_inset

 which we call the End-C Constraint.
 Lastly, we can prescribe the ordering constraint 
\begin_inset Formula $c_{1}^{(j)}<c_{2}^{(j)}<c_{3}^{(j)}<c_{4}^{(j)}$
\end_inset

 which we denote as the Inequality-C Constraint.
 
\end_layout

\begin_layout Standard
The resulting problem is a nonlinear programming problem with 44 variables
 and 42-48 constraint equations.
 The objective function is the two-dimensional integral of a discontinuous
 function which is determined by a polynomial of in 
\begin_inset Formula $z$
\end_inset

 and 
\begin_inset Formula $w$
\end_inset

 with approximately 3 million coefficients.
 To numerically approximate this function, we calculated the characteristic
 function on a grid with even spacing 
\begin_inset Formula $dx$
\end_inset

 using a CUDA kernel and found numerical solutions to the optimization problem
 using the JuMP framework with the NLopt backend.
 A mixed approach using many solutions of the semi-local optimizer LN_AUGLAG_EQ
 and fewer solutions from the global optimizer GN_ISRES were used to approximate
 the optimality of solutions.
 
\end_layout

\begin_layout Standard
The parameters 
\begin_inset Formula $N$
\end_inset

 and 
\begin_inset Formula $M$
\end_inset

 are the bounds on the stability region, but also represent a tradeoff between
 the stability in the drift and the stability in the diffusion.
 A method which is optimized when 
\begin_inset Formula $M$
\end_inset

 is small would be highly stable in the case of small noise, but would not
 be guaranteed to have good stability properties in the presence of large
 noise.
 Thus these parameters are knobs for tuning the algorithms for specific
 situations, and thus we solved the problem for different combinations of
 
\begin_inset Formula $N$
\end_inset

 and 
\begin_inset Formula $M$
\end_inset

 to determine different algorithms for the different cases.
\end_layout

\begin_layout Subsection
Approximately-Optimal Methods
\end_layout

\begin_layout Standard
The coefficients generated for approximately-optimal methods fall into three
 categories.
 In one category we have the drift-dominated stability methods where large
 
\begin_inset Formula $N$
\end_inset

 and small 
\begin_inset Formula $M$
\end_inset

 was optimized.
 On the other end we have the diffusion-dominated stability methods where
 large 
\begin_inset Formula $M$
\end_inset

 and small 
\begin_inset Formula $N$
\end_inset

 was optimized.
 Then we have the mixed stability methods which used some mixed size choices
 for 
\begin_inset Formula $N$
\end_inset

 and 
\begin_inset Formula $M$
\end_inset

.
 
\end_layout

\begin_layout Subsubsection
Drift-Dominated Stability Methods
\end_layout

\begin_layout Standard
Just a bunch of pictures? Tables?
\end_layout

\begin_layout Subsubsection
Mixed Stability Methods
\end_layout

\begin_layout Standard
Just a bunch of pictures? Tables?
\end_layout

\begin_layout Subsubsection
Diffusion-Dominated Stability Methods
\end_layout

\begin_layout Standard
Just a bunch of pictures? Tables?
\end_layout

\begin_layout Section
Approximately-Optimal Methods with Stability Detection and Switching Behaviors
\end_layout

\begin_layout Standard
In many real-world cases, one may not be able to clearly identify a model
 as drift-stability bound or diffusion-stability bound.
 In fact, many models may switch between such extremes.
 An example is a model with stochastic switching between different steady
 states.
 In this case, we have that the diffusion term 
\begin_inset Formula $f(t,X_{ss})\approx0$
\end_inset

 in the area of many stochastic steady states, meaning that while straddling
 a steady state the integration is heavily diffusion-stability dominated.
 However, when switching between steady states, 
\begin_inset Formula $f$
\end_inset

 can be very large and stiff, causing the integration to be heavily drift-stabil
ity dominated.
 Since these switches are random, the ability to adapt between these two
 behaviors could be key to achieving optimal performance.
 Given the tradeoff between drift-stability and diffusion-stability, we
 investigated methods for switching between methods which optimize for the
 different situations.
 
\end_layout

\begin_layout Standard
The basis for our method is a straight-forward extension of a method proposed
 for deterministic differential equations.
 The idea is to create a cheap approximation to the dominant eigenvalues
 of the Jacobians for the drift and diffusion terms.
 If 
\begin_inset Formula $v$
\end_inset

 is the eigenvector of the respective Jacobian, then for 
\begin_inset Formula $\Vert v\Vert$
\end_inset

 sufficiently small,
\begin_inset Formula 
\[
\left|\lambda_{D}\right|\approx\frac{\Vert f(t,x+v)-f(t,x)\Vert}{\Vert v\Vert},\thinspace\thinspace\thinspace\left|\lambda_{N}\right|\approx\frac{\Vert g(t,x+v)-g(t,x)\Vert}{\Vert v\Vert}
\]

\end_inset

 where 
\begin_inset Formula $\left|\lambda_{D}\right|$
\end_inset

 and 
\begin_inset Formula $\left|\lambda_{N}\right|$
\end_inset

 are the estimates of the dominant eigenvalues for the deterministic and
 noise functions respectively.
 We have in approximation that 
\begin_inset Formula $H_{i}^{(k)}$
\end_inset

 is an approximation for 
\begin_inset Formula $X_{t+c_{i}^{(k)}h}$
\end_inset

 and thus the difference between two successive approximations at the same
 timepoint, 
\begin_inset Formula $c_{i}^{(k)}=c_{j}^{(k)}$
\end_inset

, then the following serves as a local Jacobian estimate:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\left|\lambda_{D}\right|\approx\frac{\Vert f(t+c_{i}^{(0)}h,H_{i}^{(0)})-f(t+c_{j}^{(0)}h,H_{j}^{(0)})\Vert}{\Vert H_{i}^{(0)}-H_{j}^{(0)}\Vert},\thinspace\thinspace\thinspace\left|\lambda_{N}\right|\approx\frac{\Vert f(t+c_{i}^{(1)}h,H_{i}^{(1)})-f(t+c_{j}^{(1)}h,H_{j}^{(1)})\Vert}{\Vert H_{i}^{(1)}-H_{j}^{(1)}\Vert}
\]

\end_inset

 If we had already computed a successful step, we would like to know if
 in the next calculation we should switch methods due to stability.
 Thus it makes sense to approximate the Jacobian at the end of the interval,
 meaning 
\begin_inset Formula $i=s$
\end_inset

 and 
\begin_inset Formula $j=s-1$
\end_inset

 where 
\begin_inset Formula $s$
\end_inset

 is the number of stages.
 Then if 
\begin_inset Formula $z_{min}$
\end_inset

 is the minimum 
\begin_inset Formula $z\in\mathbb{R}$
\end_inset

 such that 
\begin_inset Formula $z$
\end_inset

 is in the stability region for the method, 
\begin_inset Formula $\frac{h\left|\lambda_{D}\right|}{z_{min}}>1$
\end_inset

 when the steps are outside the stability region.
 Because the drift and mixed stability methods do not track the noise axis
 directly, we instead modify 
\begin_inset Formula $w_{min}$
\end_inset

 to be 
\begin_inset Formula $\frac{2}{3}$
\end_inset

 of the maximum of the stability region in the noise axis.
 
\end_layout

\begin_layout Itemize
EQ_C methods
\end_layout

\begin_layout Itemize
Stability limit calculations
\end_layout

\begin_layout Itemize
Split error estimator
\end_layout

\begin_layout Section
Numerical Results
\end_layout

\begin_layout Itemize
Convergence charts?
\end_layout

\begin_layout Itemize
Efficiency on Oval2 problem?
\end_layout

\begin_layout Itemize
Show divergence of SRA1?
\end_layout

\begin_layout Section
Discussion
\end_layout

\begin_layout Itemize
3rd stage additive
\end_layout

\begin_layout Itemize
Implicit diagonal
\end_layout

\begin_layout Itemize
non-commutative and commutative
\end_layout

\begin_layout Itemize
principle truncation
\end_layout

\begin_layout Section
Appendix: Derivations
\end_layout

\begin_layout Standard

\size tiny
\begin_inset Formula 
\begin{eqnarray*}
\left(I-\mu\Delta tA^{(0)}\right)H^{(0)} & = & U_{n}+\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)^{-1}\left(U_{n}+\mu\Delta tA^{(1)}H^{(0)}\right),\\
\left(I-\mu\Delta tA^{(0)}\right)H^{(0)}-\left[\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)^{-1}\right]\mu\Delta tA^{(1)}H^{(0)} & = & U_{n}+\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)^{-1}U_{n}\\
\left(I-\mu\Delta tA^{(0)}-\mu\Delta tA^{(1)}\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)^{-1}\right)H^{(0)} & = & \left(I+\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)^{-1}\right)U_{n}\\
H^{(0)} & = & \left(I-\mu\Delta tA^{(0)}-\mu\sigma I_{(1,0)}A^{(1)}B^{(0)}\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)^{-1}\right)^{-1}\left(I+\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)^{-1}\right)U_{n}
\end{eqnarray*}

\end_inset


\begin_inset Formula 
\begin{eqnarray*}
\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)H^{(1)} & = & U_{n}+\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\left(U_{n}+\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}H^{(1)}\right)\\
\left(I-\sigma\sqrt{\Delta t}B^{(1)}-\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\right)H^{(1)} & = & U_{n}+\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}U_{n}\\
\left(I-\sigma\sqrt{\Delta t}B^{(1)}-\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\right)H^{(1)} & = & \left(I+\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\right)U_{n}\\
H^{(1)} & = & \left(I-\sigma\sqrt{\Delta t}B^{(1)}-\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\right)^{-1}\left(I+\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\right)U_{n}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard

\size tiny
\begin_inset Formula 
\begin{eqnarray*}
U_{n+1} & = & U_{n}+\mu\Delta t\left(\alpha\cdot\left[\left(I-\mu\Delta tA^{(0)}-\mu\sigma I_{(1,0)}A^{(1)}B^{(0)}\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)^{-1}\right)^{-1}\left(I+\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)^{-1}\right)\right]U_{n}\right)\\
 &  & +\sigma I_{(1)}\left(\beta^{(1)}\cdot\left[\left(I-\sigma\sqrt{\Delta t}B^{(1)}-\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\right)^{-1}\left(I+\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\right)\right]U_{n}\right)\\
 &  & +\sigma\frac{I_{(1,1)}}{\sqrt{\Delta t}}\left(\beta^{(2)}\cdot\left[\left(I-\sigma\sqrt{\Delta t}B^{(1)}-\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\right)^{-1}\left(I+\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\right)\right]U_{n}\right)\\
 &  & +\sigma\frac{I_{(1,0)}}{\Delta t}\left(\beta^{(3)}\cdot\left[\left(I-\sigma\sqrt{\Delta t}B^{(1)}-\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\right)^{-1}\left(I+\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\right)\right]U_{n}\right)\\
 &  & +\sigma\frac{I_{(1,1,1)}}{\Delta t}\left(\beta^{(4)}\cdot\left[\left(I-\sigma\sqrt{\Delta t}B^{(1)}-\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\right)^{-1}\left(I+\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\right)\right]U_{n}\right)
\end{eqnarray*}

\end_inset


\size default
 Thus we substitute in the Wiktorsson approximations
\begin_inset Formula 
\begin{align*}
I_{(1,1)} & =\frac{1}{2}\left(\Delta W^{2}-h\right)\\
I_{(1,1,1)} & =\frac{1}{6}\left(\Delta W^{3}-3h\Delta W\right)\\
I_{(1.0)} & =\frac{1}{2}h\left(\Delta W+\frac{1}{\sqrt{3}}\Delta Z\right)
\end{align*}

\end_inset

 where 
\begin_inset Formula $\Delta Z\sim N(0,h)$
\end_inset

 is independent of 
\begin_inset Formula $\Delta W\sim N(0,h)$
\end_inset

.
 By the properties of the normal distribution, we have that
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E\left[\left(\Delta W\right)^{n}\right]=0
\]

\end_inset

 for any odd 
\begin_inset Formula $n$
\end_inset

 and
\begin_inset Formula 
\begin{eqnarray*}
E\left[\left(\Delta W\right)^{2}\right] & = & h\\
E\left[\left(\Delta W\right)^{4}\right] & = & 3h^{2}\\
E\left[\left(\Delta W\right)^{6}\right] & = & 15h^{3}\\
E\left[\left(\Delta W\right)^{8}\right] & = & 105h^{4}.
\end{eqnarray*}

\end_inset


\end_layout

\end_body
\end_document
