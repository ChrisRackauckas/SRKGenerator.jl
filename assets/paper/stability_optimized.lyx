#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{multicol} 
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\rightmargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Stability-Optimized High Strong Order Methods for Stochastic Differential
 Equations with Additive and Diagonal Noise
\end_layout

\begin_layout Author
Chris Rackauckas and Qing Nie
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Stochastic differential equations have seen increasing use in scientific
 fields such as biology and climate science due to their ability to capture
 the randomness inherent in physical systems.
 These equations are of the general form:
\begin_inset Formula 
\[
dX_{t}=f(t,X_{t})dt+g(t,X_{t})dW_{t}
\]

\end_inset

where 
\begin_inset Formula $X_{t}$
\end_inset

 is a 
\begin_inset Formula $d$
\end_inset

-dimensional vector, where 
\begin_inset Formula $f:\mathbb{R}^{d}\rightarrow\mathbb{R}^{d}$
\end_inset

 is the drift coefficient and 
\begin_inset Formula $g:\mathbb{R}^{d}\rightarrow\mathbb{R}^{d\times m}$
\end_inset

 is a matrix equation known as the diffusion coefficient which describes
 the amount and mixtures of the noise process 
\begin_inset Formula $W_{t}$
\end_inset

 which is a 
\begin_inset Formula $m$
\end_inset

-dimensional Brownian motion.
 In many models, noise is added to deterministic equations phenomenologically.
 These models are numerically studied for their qualitatative behavior:
 scientists are interested not in numerical predictions exact to many decimal
 places but to understand the phonomena which only occurs in the presence
 of stochasticity, like random switching between cell types.
 In these cases, the noise process can be modeled as exogenous to the system
 and thus not dependent the system itself, leading to the assumption that
 
\begin_inset Formula $g(t,X_{t})\equiv g(t)$
\end_inset

 which is known as additive noise.
 Another common case is multiplicative noise, where to each deterministic
 equation a noise term 
\begin_inset Formula $\sigma_{i}X_{t}^{i}dW_{t}$
\end_inset

 is added to give proportional noise.
 This results in 
\begin_inset Formula $g(t,X_{t})$
\end_inset

 being the diagonal matrix 
\begin_inset Formula $\left(\sigma_{i}X_{t}^{i}\right)$
\end_inset

 and thus falling into the more general category of diagonal noise.
\end_layout

\begin_layout Standard
The unique features of stochastic models in many cases are pathwise-dependent.
 The mean of a chemical reaction network may stay at a constant steady state,
 but in the presence of randomness this may be switching between various
 states.
 These pathwise properties are of interest because they capture the effects
 which cannot be found in deterministic models.
 However, these same effects exhibit numerical difficulties.
 Almost by definition these features exist in the single trajectories of
 the random processes and thus must be controlled individually.
 These trajectories display large, transient and random switching behavior
 which in a given trajectory causes stochastic bursts of numerical stiffness,
 a phonomena which we will denote pathwise stiffness.
 In previous work, the authors have shown that by using adaptive timestepping
 a stochastic reaction network of 19 reactants is able to be solve with
 an average timestep 100,000x larger than the value that was found necessary
 for stability.
 However, the methods were still largely 
\begin_inset Quotes eld
\end_inset

stability-bound
\begin_inset Quotes erd
\end_inset

, that is the tolerance was set to solve the model was determined by what
 was necessary for stability but was far below the error necessary for the
 application.
 The purpose of this investigation is to develop numerical methods with
 the ability to properly handle pathwise stiffness and allow for efficient
 solving of large Monte Carlo experiments.
 We approach this through two means.
 On one end we develop stability-optimized Stochastic Runge-Kutta (SRK)
 methods which have the property of having drastically enlarged stability
 regions.
 Similar to the Runge-Kutta Chebyschev (and the S-ROCK extension to the
 stochastic case), these methods are designed to be efficient for equations
 which display stiffness without fully commiting to implicit solvers.
 On the otherhand, to handle extreme stiffness we develop an implicit RK
 method for additive noise problems.
 We show that this method is A-L stable in a generalization of these terms
 to additive noise SDEs.
 To extend the utility of these methods, we derive and extension of the
 methods for additive SDEs to multiplicative SDEs through a transformation.
 In addition to the new methods, we display a novel scalable mechanism for
 the derivation of 
\begin_inset Quotes eld
\end_inset

optimal
\begin_inset Quotes erd
\end_inset

 Runge-Kutta methods, and use it to design stability-optimized methods for
 diagonal noise SDEs which would otherwise be analytically intractable due
 to the few million terms in the stability equation.
 Lastly, we show that on test problems that these methods are no less efficient
 than existing SRK methods when one only requires a few decimal places of
 accuracy (
\begin_inset Formula $>10^{-6}$
\end_inset

), but show that these methods have two to three times the stability region,
 allowing them to dramatically speed up computations on stability-bound
 problems.
\end_layout

\begin_layout Section
Adaptive Strong Order 1.0/1.5 SRK Methods
\end_layout

\begin_layout Standard
The class of methods we wish to example are the Strong Order 1.5 SRK methods
 due to Rossler.
 The diagonal noise methods utilize the same general form and order conditions
 as the methods for scalar noise so we use their notation for simplicity.
 The strong order 1.5 methods for scalar noise are of the form
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
X_{n+1}=X_{n}+\sum_{i=1}^{s}\alpha_{i}f\left(t_{n}+c_{i}^{(0)}h,H_{i}^{(0)}\right)+\sum_{i=1}^{s}\left(\beta_{i}^{(1)}I_{(1)}+\beta_{i}^{(2)}\frac{I_{(1,1)}}{\sqrt{h}}+\beta_{i}^{(3)}\frac{I_{(1,0)}}{h}+\beta_{i}^{(4)}\frac{I_{(1,1,1)}}{h}\right)g\left(t_{n}+c_{i}^{(1)}h\right)
\]

\end_inset

 with stages
\begin_inset Formula 
\begin{align*}
H_{i}^{(0)} & =X_{n}+\sum_{j=1}^{s}A_{ij}^{(0)}f\left(t_{n}+c_{j}^{(0)}h,H_{j}^{(0)}\right)h+\sum_{j=1}^{s}B_{ij}^{(0)}g\left(t_{n}+c_{j}^{(1)}h,H_{j}^{(1)}\right)\frac{I_{(1,0)}}{h}\\
H_{i}^{(1)} & =X_{n}+\sum_{j=1}^{s}A_{ij}^{(1)}f\left(t_{n}+c_{j}^{(0)}h,H_{j}^{(0)}\right)h+\sum_{j=1}^{s}B_{ij}^{(1)}g\left(t_{n}+c_{j}^{(1)}h,H_{j}^{(1)}\right)\sqrt{h}
\end{align*}

\end_inset

 where the 
\begin_inset Formula $I_{j}$
\end_inset

 are the Wiktorsson approximations to the iterated stochastic integrals.
 In the case of additive noise, this reduces to the form
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
X_{n+1}=X_{n}+\sum_{i=1}^{s}\alpha_{i}f\left(t_{n}+c_{i}^{(0)}h,H_{i}^{(0)}\right)+\sum_{i=1}^{s}\left(\beta_{i}^{(1)}I_{(1)}+\beta_{i}^{(2)}\frac{I_{(1,0)}}{h}\right)g\left(t_{n}+c_{i}^{(1)}h\right)
\]

\end_inset

 with stages
\begin_inset Formula 
\[
H_{i}^{(0)}=X_{n}+\sum_{j=1}^{s}A_{ij}^{(0)}f\left(t_{n}+c_{j}^{(0)}h,H_{j}^{(0)}\right)h+\sum_{j=1}^{s}B_{ij}^{(0)}g\left(t_{n}+c_{j}^{(1)}h\right)\frac{I_{(1,0)}}{h}.
\]

\end_inset

 The tuple of coefficients 
\begin_inset Formula $\left(A^{(j)},B^{(j)},\beta^{(j)},\alpha\right)$
\end_inset

 thus fully determine the SRK method.
 These coefficients are subject to the constraint equations:
\end_layout

\begin_layout Standard
The coefficients 
\begin_inset Newline newline
\end_inset


\begin_inset Formula $\left(A_{0},B_{0},\beta^{(i)},\alpha\right)$
\end_inset

 must satisfy the following order conditions to achieve order .5:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{multicols}{3}
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\alpha^{T}e=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(1)^{T}}e=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(2)^{T}}e=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(3)^{T}}e=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(4)^{T}}e=0$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{multicols}
\end_layout

\end_inset

 additionally, for order 1:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{multicols}{2}
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(1)^{T}}B^{(1)}e=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(2)^{T}}B^{(1)}e=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(3)^{T}}B^{(1)}e=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(4)^{T}}B^{(1)}e=0$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{multicols}
\end_layout

\end_inset

 and lastly for order 1.5:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{multicols}{2}
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\alpha^{T}A^{(0)}e=\frac{1}{2}$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\alpha^{T}B^{(0)}e=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\alpha^{T}\left(B^{(0)}e\right)^{2}=\frac{3}{2}$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(1)^{T}}A^{(1)}e=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(2)^{T}}A^{(1)}e=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(3)^{T}}A^{(1)}e=-1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(4)^{T}}A^{(1)}e=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(1)^{T}}\left(B^{(1)}e\right)^{2}=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(2)^{T}}\left(B^{(1)}e\right)^{2}=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(3)^{T}}\left(B^{(1)}e\right)^{2}=-1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(4)^{T}}\left(B^{(1)}e\right)^{2}=2$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(1)^{T}}\left(B^{(1)}\left(B^{(1)}e\right)\right)=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(2)^{T}}\left(B^{(1)}\left(B^{(1)}e\right)\right)=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(3)^{T}}\left(B^{(1)}\left(B^{(1)}e\right)\right)=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(4)^{T}}\left(B^{(1)}\left(B^{(1)}e\right)\right)=1$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{multicols}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
16.\thinspace\thinspace\thinspace\frac{1}{2}\beta^{(1)^{T}}\left(A^{(1)}\left(B^{(0)}e\right)\right)+\frac{1}{3}\beta^{(3)^{T}}\left(A^{(1)}\left(B^{(0)}e\right)\right)=0
\]

\end_inset

where 
\begin_inset Formula $f,g\in C^{1,2}(\mathcal{I}\times\mathbb{R}^{d},\mathbb{R}^{d})$
\end_inset

, 
\begin_inset Formula $c^{(i)}=A^{(i)}e$
\end_inset

, 
\begin_inset Formula $e=(1,1,1,1)^{T}$
\end_inset

.
 The reduced constraints for additive noise were derived for order 1:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{multicols}{3}
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\alpha^{T}e=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(1)^{T}}e=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(2)^{T}}e=0$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{multicols}
\end_layout

\end_inset

 and the additional conditions for order 1.5:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{multicols}{3}
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\alpha^{T}B^{(0)}e=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\alpha^{T}A^{(0)}e=\frac{1}{2}$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\alpha^{T}\left(B^{(0)}e\right)^{2}=\frac{3}{2}$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(1)^{T}}c^{(1)}=1$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\beta^{(2)^{T}}c^{(1)}=-1$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{multicols}
\end_layout

\end_inset

where 
\begin_inset Formula $c^{(0)}=A^{(0)}e$
\end_inset

 with 
\begin_inset Formula $f\in C^{1,3}(\mathcal{I}\times\mathbb{R}^{d},\mathbb{R}^{d})$
\end_inset

 and 
\begin_inset Formula $g\in C^{1}(\mathcal{I},\mathbb{R}^{d})$
\end_inset

.
\end_layout

\begin_layout Standard
Rackauckas and Nie showed that for any method of this form, there exists
 an error estimator
\begin_inset Formula 
\[
E=\delta E_{D}+E_{N}
\]

\end_inset

 where 
\begin_inset Formula $E_{D}$
\end_inset

 is the deterministic (drift) error estimator and 
\begin_inset Formula $E_{N}$
\end_inset

 is the noise error estimator, given respectively by
\begin_inset Formula 
\begin{align*}
E_{D} & =\left|h\sum_{i\in I_{1}}\left(-1\right)^{\sigma(i)}f\left(t_{n}+c_{i}^{(0)}h,H_{i}^{(0)}\right)\right|\\
E_{N} & =\left|\sum_{i\in I_{1}}\left(\beta_{i}^{(3)}\frac{I_{(1,0)}}{h}+\beta_{i}^{(4)}\frac{I_{(1,1,1)}}{h}\right)g\left(t_{n}+c_{i}^{(1)}h,H_{i}^{(1)}\right)\right|
\end{align*}

\end_inset

with some constraints on 
\begin_inset Formula $\sigma(i)$
\end_inset

 and the 
\begin_inset Formula $I_{j}$
\end_inset

.
 Thus unlike in the theory of ordinary differential equations, the choice
 of coefficients for SRK methods does not require explicitly finding an
 embedded method.
 This gives the means to extend any SRK method to an adaptive timestepping
 method which was shown to be fundamental for the transient behavior of
 pathwise stiffness.
\end_layout

\begin_layout Section
Optimized-Stability High Order SRK Methods with Additive Noise
\end_layout

\begin_layout Standard
Using the terms as defined by Kloden and Platen, we define a discrete approximat
ion as numerically stable if for any finite time interval 
\begin_inset Formula $\left[t_{0},T\right]$
\end_inset

, there exists a positive constant 
\begin_inset Formula $\Delta_{0}$
\end_inset

 such that for each 
\begin_inset Formula $\epsilon>0$
\end_inset

 and each 
\begin_inset Formula $\delta\in\left(0,\Delta_{0}\right)$
\end_inset

 
\begin_inset Formula 
\[
\lim_{\left|X_{0}^{\delta}-\bar{X}_{0}^{\delta}\right|\rightarrow0}\sup_{t_{0}\leq t\leq T}P\left(\left|X_{t}^{\delta}-\bar{X}_{t}^{\delta}\right|\geq\epsilon\right)=0
\]

\end_inset

 where 
\begin_inset Formula $X_{n}^{\delta}$
\end_inset

 is a discrete time approximation with maximum step size 
\begin_inset Formula $\delta>0$
\end_inset

 starting at 
\begin_inset Formula $X_{0}^{\delta}$
\end_inset

 and 
\begin_inset Formula $\bar{X}_{n}^{\delta}$
\end_inset

 respectively starting at 
\begin_inset Formula $\bar{X}_{n}^{\delta}$
\end_inset

.
 For additive noise, we consider the complex-valued linear test equations
\begin_inset Formula 
\[
dX_{t}=\mu X_{t}dt+dW_{t}
\]

\end_inset

 where 
\begin_inset Formula $\lambda$
\end_inset

 is a complex number.
 In this framework, a scheme which can be written in the form 
\begin_inset Formula 
\[
X_{n+1}^{h}=X_{n}^{h}G\left(\mu h\right)+Z_{n}^{\delta}
\]

\end_inset

with a constant step size 
\begin_inset Formula $\delta\equiv h$
\end_inset

 and 
\begin_inset Formula $Z_{n}^{\delta}$
\end_inset

 are random variables which do not depend on the 
\begin_inset Formula $Y_{n}^{\delta}$
\end_inset

, then the region of absolute stability is the set where for 
\begin_inset Formula $z=\mu h$
\end_inset

, 
\begin_inset Formula $\left|G(z)\right|<1$
\end_inset

.
 
\end_layout

\begin_layout Standard
The additive SRK method can be written as
\begin_inset Formula 
\[
X_{n+1}^{h}=X_{n}^{h}+z\left(\alpha\cdot H^{(0)}\right)+\beta^{(1)}\sigma I_{(1)}+\sigma\beta^{(2)}\frac{I_{(1,0)}}{h}
\]

\end_inset

 where
\begin_inset Formula 
\[
H^{(0)}=\left(I-zA^{(0)}\right)^{-1}\left(\hat{X_{n}^{h}}+B^{(0)}e\sigma\frac{I_{(1,0)}}{h}\right)
\]

\end_inset

where 
\begin_inset Formula $\hat{X_{n}^{h}}$
\end_inset

 is the size 
\begin_inset Formula $s$
\end_inset

 constant vector of elements 
\begin_inset Formula $X_{n}^{h}$
\end_inset

 and 
\begin_inset Formula $e=\left(1,1,1,1\right)^{T}$
\end_inset

.
 By substitution we receive
\begin_inset Formula 
\[
X_{n+1}^{h}=X_{n}^{h}\left(1+z\left(\alpha\cdot\left(I-zA^{(0)}\right)^{-1}\right)\right)+\left(I-zA^{(0)}\right)^{-1}B^{(0)}e\sigma\frac{I_{(1,0)}}{h}+\beta^{(1)}\sigma I_{(1)}+\sigma\beta^{(2)}\frac{I_{(1,0)}}{h}
\]

\end_inset

This set of equations decouples to the form of Equation ## since the iterated
 stochastic integral approximation 
\begin_inset Formula $I_{j}$
\end_inset

 are random numbers and are independent of the 
\begin_inset Formula $X_{n}^{h}$
\end_inset

.
 Thus the stability condition is determined by the equation
\begin_inset Formula 
\[
G(z)=1+z\left(\alpha\cdot\left(I-zA^{(0)}\right)^{-1}\right).
\]

\end_inset


\end_layout

\begin_layout Subsection
Stability-Optimal 2-Stage Explicit SRA Methods
\end_layout

\begin_layout Standard
For explicit methods, the 
\begin_inset Formula $A^{(i)}$
\end_inset

 and 
\begin_inset Formula $B^{(i)}$
\end_inset

 are lower diagonal and we receive the simplified stability function 
\begin_inset Formula 
\[
G(z)=1+A_{21}z^{2}\alpha_{2}+z\left(\alpha_{1}+\alpha_{2}\right)
\]

\end_inset

 for a two-stage additive noise SRK method.
 For this method we will find the method which optimizes the stability in
 the real part of 
\begin_inset Formula $z$
\end_inset

.
 Thus we wish to find 
\begin_inset Formula $A^{(0)},\alpha$
\end_inset

 s.t.
 the negative real roots of 
\begin_inset Formula $\left|G(z)\right|=1$
\end_inset

 are minimized.
 By the quadratic equation we see that there exists only a single negative
 root: 
\begin_inset Formula $z=\frac{1-\sqrt{1+8\alpha_{2}}}{2\alpha_{2}}$
\end_inset

.
 Using Mathematica's minimum function, we determine that the minimum value
 for this root subject to the order constraints is 
\begin_inset Formula $z=\frac{3}{4}\left(1-\sqrt{\frac{19}{3}}\right)\approx-1.13746$
\end_inset

.
 We see that this is achieved when 
\begin_inset Formula $\alpha=\frac{2}{3}$
\end_inset

, meaning that the SRA1 method due to Rossler achieves the maximum stability
 criteria.
 However, given extra degrees of freedom, we attempted to impose that 
\begin_inset Formula $c_{1}^{(0)}=c_{1}^{(1)}=0$
\end_inset

 and 
\begin_inset Formula $c_{2}^{(0)}=c_{2}^{(1)}=1$
\end_inset

 so that the error estimator spans the whole interval.
 This can lead to improved robustness of the adaptive error estimator.
 In fact, when trying to optimize the error estimator's span we find that
 there is no error estimator which satisfies 
\begin_inset Formula $c_{2}^{(0)}>\frac{3}{4}$
\end_inset

 which is the span of the SRA1 method.
 Thus the SRA1 is the stability-optimized 2-stage explicit method which
 achieves the most robust error estimator.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
A^{(0)} & =\left(\begin{array}{cc}
0 & 0\\
\frac{3}{4} & 0
\end{array}\right),\thinspace\thinspace\thinspace B^{(0)}=\left(\begin{array}{cc}
0 & 0\\
\frac{3}{2} & 0
\end{array}\right),\thinspace\thinspace\thinspace\thinspace\alpha=\left(\begin{array}{c}
\frac{1}{3}\\
\frac{2}{3}
\end{array}\right)\\
\beta^{(1)} & =\left(\begin{array}{c}
1\\
0
\end{array}\right),\thinspace\thinspace\thinspace\beta^{(2)}=\left(\begin{array}{c}
-1\\
1
\end{array}\right),\thinspace\thinspace\thinspace c^{(0)}=\left(\begin{array}{c}
0\\
\frac{3}{4}
\end{array}\right),\,\,\,c^{(1)}=\left(\begin{array}{c}
1\\
0
\end{array}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Stability-Optimal 3-Stage Explicit SRA Methods
\end_layout

\begin_layout Standard
For the 3-stage SRA method, we recieve the simplified stability function
\begin_inset Formula 
\[
G(z)=A_{21}A_{31}\alpha_{3}z^{3}+A_{21}\alpha_{2}z^{2}+A_{31}\alpha_{3}z^{2}+A_{32}\alpha_{3}z^{2}+\alpha_{1}z+\alpha_{2}z+\alpha_{3}z+1
\]

\end_inset

 To optimize this method, we attempted to use the same techniques as before
 and optimize the real values of the negative roots.
 However, in this case we have a cubic polynomial and the root equations
 are more difficult.
 In the Mathematica notebooks we should that one root condition can be discarded
, but the other two had difficulties optimizing.
 Instead, we turn to a more general technique to handle the stability optimizati
on which will be employed in later sections as well.
 To do so, we generate an optimization problem which we can numerically
 solve for the coefficients.
 To simplify the problem, we let 
\begin_inset Formula $z\in\mathbb{R}$
\end_inset

.
 Define the function:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
f\left(z,w;N,M\right)=\int_{D}\chi_{G(z)\leq1}(z)dz
\]

\end_inset

Notice that for 
\begin_inset Formula $D\rightarrow\mathbb{C}$
\end_inset

, 
\begin_inset Formula $f$
\end_inset

 is the area of the stability region.
 Thus we define the stability-optimized diagonal SRK method as the set of
 coefficients which achieves
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\max_{A^{(i)},B^{(i)},\beta^{(i)},\alpha} & f(z)\\
\text{subject to: } & \text{Order Constraints}
\end{align*}

\end_inset

In all cases we impose 
\begin_inset Formula $0<c_{i}^{(0)},c_{i}^{(1)}<1$
\end_inset

.
 We use the order constraints to simplify the problem to an nonlinear optimizati
on problem on 14 variables with 3 equality constraints and 4 inequality
 constraints (with bound constraints on the 10 variables).
 However, we found that simplifying the problem even more to require 
\begin_inset Formula $c_{1}^{(0)}=c_{1}^{(1)}=0$
\end_inset

 and 
\begin_inset Formula $c_{3}^{(0)}=c_{3}^{(1)}=1$
\end_inset

 did not significantly impact the stability regions but helps the error
 estimator and thus we reduced the problem to 10 variables, 3 equality constrain
ts, and 2 inequality constraints.
 This was optimized using the COBYLA local optimization algorithm with randomize
d initial conditions 100 times and all gave similar results.
 In the Mathematica notebook we show the effect of changing the numerical
 integration region 
\begin_inset Formula $D$
\end_inset

 on the results, but conclude that a 
\begin_inset Formula $D$
\end_inset

 which does not bias the result for better/worse real/complex handling does
 not improve the result.
 The resulting algorithm, SOSRA, we given by the coefficients in Table X
 in the appendix.
 Lastly, we used the condition that 
\begin_inset Formula $c_{2}^{(0)}=c_{3}^{(0)}=c_{2}^{(1)}=c_{3}^{(1)}=1$
\end_inset

 to allow for free stability detection.
 The method generated with this extra constraint is SOSRA2.
 These methods have their stability regions compared to SRA1 and SRA3 in
 Figure X where it is shown that the SOSRA methods more than doubles the
 allowed real eigenvalues.
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename C:/Users/Chris/.julia/v0.6/SRKGenerator/assets/obj_poly_solve/SOSRA_stability.pdf

\end_inset


\end_layout

\begin_layout Subsection
An A-Stable L-Stable 2-Stage (Semi-)Implicit SRA Method
\end_layout

\begin_layout Standard
It's clear that, as in the case for deterministic equations, the explicit
 methods cannot be made A-stable.
 However, the implicit two-stage additive noise SRK method is determined
 by
\begin_inset Formula 
\[
G(z)=\frac{z(A_{11}(A_{22}z-\alpha_{2}z-1)+A_{12}z(\alpha_{1}-A_{21})+A_{21}\ensuremath{\alpha_{2}}z-A_{22}(\alpha_{1}z+1)+\alpha_{1}+\alpha_{2})+1}{A_{11}z(A_{22}z-1)-z(A_{12}A_{21}z+A_{22})+1}
\]

\end_inset

 which is 
\begin_inset Formula $A$
\end_inset

-stable if 
\begin_inset Formula 
\[
A_{11}z(A_{22}z-1)-z(A_{12}A_{21}z+A_{22})+1>z(A_{11}(A_{22}z-\alpha_{2}z-1)+A_{12}z(\alpha_{1}-A_{21})+A_{21}\ensuremath{\alpha_{2}}z-A_{22}(\alpha_{1}z+1)+\alpha_{1}+\alpha_{2})+1.
\]

\end_inset

 Notice that the numerator equals the denominator if and only if 
\begin_inset Formula $z=0$
\end_inset

 or
\begin_inset Formula 
\[
z=\frac{\alpha_{1}+\alpha_{2}}{\left(A_{22}-A_{12}\right)\alpha_{1}+\left(A_{11}-A_{21}\right)\alpha_{2}}.
\]

\end_inset

 From the order conditions we know that 
\begin_inset Formula $\alpha_{1}+\alpha_{2}=1$
\end_inset

 which means that no root exists with 
\begin_inset Formula $Re(z)<0$
\end_inset

 if 
\begin_inset Formula $\left(A_{22}-A_{12}\right)\alpha_{1}+\left(A_{11}-A_{21}\right)\alpha_{2}>0$
\end_inset

.
 Thus under these no roots conditions, we can determine A-stability by checking
 the inequality at 
\begin_inset Formula $z=1$
\end_inset

, which gives 
\begin_inset Formula $1>\left(A_{22}-A_{12}\right)\alpha_{1}+\left(A_{11}-A_{21}\right)\alpha_{2}$
\end_inset

.
 Using the order condition, we have a total of four constraints on the 
\begin_inset Formula $A^{(0)}$
\end_inset

 and 
\begin_inset Formula $\alpha$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\left(A_{11}+A_{12}\right)\alpha_{1}+\left(A_{21}+A_{22}\right)\alpha_{2} & =\frac{1}{2}\\
\alpha_{1}+\alpha_{2} & =1\\
0<\left(A_{22}-A_{12}\right)\alpha_{1}+\left(A_{11}-A_{21}\right)\alpha_{2} & <1
\end{align*}

\end_inset

An immediate fact we note is that none of the 2-stage (Order 3) Labatto
 or Radau methods create stochastically A-stable methods.
 Instead, we wish to derive methods which have similar properties and have
 stochastic A-stability.
 One property we extend is L-stability.
 The straightforward extension of L-stability is the condition
\begin_inset Formula 
\[
\lim_{z\rightarrow\infty}G(z)=0.
\]

\end_inset

This implies that
\begin_inset Formula 
\[
\frac{-A_{11}A_{22}+A_{11}\alpha_{2}+A_{12}A_{21}-A_{12}\alpha_{1}-A_{21}\alpha_{2}+A_{22}\alpha_{2}\alpha_{1}}{A_{12}A_{21}-A_{11}A_{22}}=0
\]

\end_inset

 The denominator is 
\begin_inset Formula $-\det(A^{(0)})$
\end_inset

 which implies 
\begin_inset Formula $A^{(0)}$
\end_inset

 must be non-singular.
 Next, we attempt to impose B-stability on the drift portion of the method.
 We use the condition due to Burrage and Butcher that for 
\begin_inset Formula $B=\text{diag}\left(\alpha_{1},\alpha_{2}\right)$
\end_inset

 
\begin_inset Formula $M=BA^{(0)}+A^{(0)}B-\alpha\alpha^{T}$
\end_inset

, we require both 
\begin_inset Formula $B$
\end_inset

 and 
\begin_inset Formula $M$
\end_inset

 to be non-negative definite.
 However, in the supplemental Mathematica notebooks we show computationally
 that there is no 2-stage SRK method of this form which satisfies all three
 of these stability conditions.
 Thus we settle for A-stability and L-stability.
\end_layout

\begin_layout Standard
Recalling that 
\begin_inset Formula $c^{(0)}$
\end_inset

 and 
\begin_inset Formula $c^{(1)}$
\end_inset

 are the locations in time where 
\begin_inset Formula $f$
\end_inset

 and 
\begin_inset Formula $g$
\end_inset

 are approximated respectively, we wish to impose
\begin_inset Formula 
\begin{align*}
c_{1}^{(0)} & =0\\
c_{2}^{(0)} & =1\\
c_{1}^{(1)} & =0\\
c_{2}^{(1)} & =1
\end{align*}

\end_inset

 so that the error estimator covers the entire interval of integration (for
 robustness to discontinuities).
 Since 
\begin_inset Formula $c^{(0)}=A^{(0)}e$
\end_inset

, this leads to the condition 
\begin_inset Formula $A_{21}+A_{22}=1$
\end_inset

.
 Using the constraint-satisfaction algorithm FindInstance in Mathematica,
 we look for tableaus which satisfy the previous conditions with the added
 constraint of semi-implicitness, i.e.
 
\begin_inset Formula $B^{(0)}$
\end_inset

 is lower triangular.
 This assumption is added becaues the inverse of the normal distribution
 has unbounded moments, and thus in many cases it mathematically simpler
 to consider the diffusion term as explicit (though there are recent methods
 which drop this requirement via truncation or extra assumptions on the
 solution).
 However, we find that there is no coefficient set which meets all of these
 requirements.
 However, if we relax the interval estimate condition to allow 
\begin_inset Formula $0\leq c_{2}^{(0)}\leq1$
\end_inset

, we find an A-L stable method:
\begin_inset Formula 
\begin{align*}
A^{(0)} & =\left(\begin{array}{cc}
-1 & 1\\
0 & \frac{3}{4}
\end{array}\right),\thinspace\thinspace\thinspace B^{(0)}=\left(\begin{array}{cc}
0 & 0\\
\frac{3}{2} & 0
\end{array}\right),\thinspace\thinspace\thinspace\thinspace\alpha=\left(\begin{array}{c}
\frac{1}{3}\\
\frac{2}{3}
\end{array}\right)\\
\beta^{(1)} & =\left(\begin{array}{c}
0\\
1
\end{array}\right),\thinspace\thinspace\thinspace\beta^{(2)}=\left(\begin{array}{c}
1\\
-1
\end{array}\right),\thinspace\thinspace\thinspace c^{(0)}=\left(\begin{array}{c}
0\\
\frac{3}{4}
\end{array}\right),\,\,\,c^{(1)}=\left(\begin{array}{c}
0\\
1
\end{array}\right)
\end{align*}

\end_inset

 If we attempt to look for an SDIRK-like method to reduce the complexity
 of the implicit equation, i.e.
 
\begin_inset Formula $A_{12}^{(0)}=0$
\end_inset

, using FindInstance we find the constraints unsatisfiable.
 Note that if we drop the semi-implicit assumption we find that the full
 constraints cannot be satisfied there (we still cannot satisfy 
\begin_inset Formula $c_{1}^{(0)}=0$
\end_inset

 and 
\begin_inset Formula $c_{2}^{(0)}=1$
\end_inset

), and there does not exist an A-L stable SDIRK method in that case.
\end_layout

\begin_layout Section
Optimized-Stability Methods for Multiplicative Noise via Transformation
\end_layout

\begin_layout Standard
Given the efficiency of the methods for additive noise, one method for developin
g efficient methods for more general noise processes is to use a transform
 of diagonal noise processes to additive noise.
 This transform is due to Lamperti, which states that the SDE of the form
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
dX_{t}=f(t,X_{t})dt+\sigma(t,X_{t})R(t)dW_{t}
\]

\end_inset

 where 
\begin_inset Formula $\sigma$
\end_inset

 a diagonal matrix with diagonal elements 
\begin_inset Formula $\sigma_{i}(t,X_{i,t})$
\end_inset

 has the transformation
\begin_inset Formula 
\[
Z_{i,t}=\psi_{i}(t,X_{i,t})=\int\frac{1}{\sigma_{i}(x,t)}dx\mid_{x=X_{i,t}}
\]

\end_inset

which will result in an Ito process with the ith element given by
\begin_inset Formula 
\[
dZ_{i,t}=\left(\frac{\partial}{\partial t}\psi_{i}(t,x)\mid_{x=\psi^{-1}(t,Z_{i,t})}+\frac{f_{i}(\psi^{-1}(t,Z_{t}),t)}{\frac{1}{2}\frac{\partial}{\partial x}\sigma_{i}\left(\psi_{i}^{-1}\left(t,Z_{i,t}\right)\right)}\right)dt+\sum_{j=1}^{n}r_{ij}(t)dw_{j,t}
\]

\end_inset

 with
\begin_inset Formula 
\[
X_{t}=\psi^{-1}\left(t,Z_{t}\right).
\]

\end_inset

 This is easily verified using Ito's Lemma.
 An example of such a transformation is multidimensional geometric Brownian
 motion, where 
\begin_inset Formula $A=diag(a_{1},a_{2})$
\end_inset

, 
\begin_inset Formula $\sigma=diag(X_{1},X_{2})$
\end_inset

, and 
\begin_inset Formula $R=r_{ij}$
\end_inset

.
 Then in this case, 
\begin_inset Formula $Z=\psi(X)=\log(X)$
\end_inset

 and
\begin_inset Formula 
\[
d\left[\begin{array}{c}
Z_{1}\\
Z_{2}
\end{array}\right]=\left[\begin{array}{c}
a_{1}-\frac{1}{2}\left(r_{11}^{2}+r_{12}^{2}\right)\\
a_{2}-\frac{1}{2}\left(r_{21}^{2}+r_{22}^{2}\right)
\end{array}\right]dt+\left[\begin{array}{cc}
r_{11} & r_{12}\\
r_{21} & r_{22}
\end{array}\right]dW_{t}.
\]

\end_inset

 This transformation requires that 
\begin_inset Formula $\sigma_{i}^{-1}(t,X_{i,t})$
\end_inset

 is one-to-one, and thus does not exist in general for diagonal noise.
 However, in the case of mixed multiplicative and additive noise: 
\begin_inset Formula 
\[
dX_{t}=f(t,X_{t})dt+\sigma X_{t}dW_{t}
\]

\end_inset

 where 
\begin_inset Formula $\sigma$
\end_inset

 is a constant diagonal matrix, then
\begin_inset Formula 
\begin{align*}
d\log X_{t} & =\tilde{f}(t,X_{t})dt+dW_{t}\\
\tilde{f}(t,X_{t}) & =\frac{f(t,X_{t})}{\sigma X_{t}}
\end{align*}

\end_inset

 where the division is considered element-wise.
 Thus we can modify the additive SRK method to be in the form
\begin_inset Formula 
\[
\log X_{n+1}=\log X_{n}+\sum_{i=1}^{s}\alpha_{i}\tilde{f}\left(t_{n}+c_{i}^{(0)}h,\exp\left(H_{i}^{(0)}\right)\right)+\sum_{i=1}^{s}\left(\beta_{i}^{(1)}I_{(1)}+\beta_{i}^{(2)}\frac{I_{(1,0)}}{h}\right)
\]

\end_inset

with stages
\begin_inset Formula 
\[
H_{i}^{(0)}=\log X_{n}+\sum_{j=1}^{s}A_{ij}^{(0)}\tilde{f}\left(t_{n}+c_{j}^{(0)}h,\exp\left(H_{j}^{(0)}\right)\right)h+\sum_{j=1}^{s}B_{ij}^{(0)}\frac{I_{(1,0)}}{h}.
\]

\end_inset

 Back-transforming this, we get
\begin_inset Formula 
\[
X_{n+1}=X_{n}\exp\left(\sum_{i=1}^{s}\alpha_{i}\tilde{f}\left(t_{n}+c_{i}^{(0)}h,\exp\left(H_{i}^{(0)}\right)\right)+\sum_{i=1}^{s}\left(\beta_{i}^{(1)}I_{(1)}+\beta_{i}^{(2)}\frac{I_{(1,0)}}{h}\right)\right)
\]

\end_inset

 where the exponentiation is interpreted element-wise.
\end_layout

\begin_layout Section
Optimized-Stability Order 1.5 SRK Methods with Diagonal Noise
\end_layout

\begin_layout Subsection
The Stability Equation for Order 1.5 SRK Methods with Diagonal Noise
\end_layout

\begin_layout Standard
For diagonal noise, we will use the mean-square definition of stability.
 A method is mean-square stable if 
\begin_inset Formula $\lim_{n\rightarrow\infty}\mathbb{E}\left(\left|X_{n}\right|^{2}\right)=0$
\end_inset

 on the test equation
\begin_inset Formula 
\[
dX_{t}=\mu X_{t}dt+\sigma X_{t}dW_{t}.
\]

\end_inset

In matrix form we can re-write our method as given by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
X_{n+1}=X_{n}+\mu h\left(\alpha\cdot H^{(0)}\right)+\sigma I_{(1)}\left(\beta^{(1)}\cdot H^{(1)}\right)+\sigma\frac{I_{(1,1)}}{\sqrt{h}}\left(\beta^{(2)}\cdot H^{(1)}\right)+\sigma\frac{I_{(1,0)}}{h}\left(\beta^{(3)}\cdot H^{(1)}\right)+\sigma\frac{I_{(1,1,1)}}{h}\left(\beta^{(4)}\cdot H^{(1)}\right)
\]

\end_inset

 with stages
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
H^{(0)} & = & X_{n}+\mu\Delta tA^{(0)}H^{(0)}+\sigma\frac{I_{(1,0)}}{h}B^{(0)}H^{(1)},\\
H^{(1)} & = & X_{n}+\mu\Delta tA^{(1)}H^{(0)}+\sigma\sqrt{\Delta t}B^{(1)}H^{(1)}
\end{eqnarray*}

\end_inset

where 
\begin_inset Formula $\hat{X_{n}}$
\end_inset

 is the size 
\begin_inset Formula $s$
\end_inset

 constant vector of 
\begin_inset Formula $X_{n}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
H^{(0)} & = & \left(I-hA^{(0)}\right)^{-1}\left(\hat{X_{n}}+\sigma\frac{I_{(1,0)}}{h}B^{(0)}H^{(1)}\right),\\
H^{(1)} & = & \left(I-\sigma\sqrt{h}B^{(1)}\right)^{-1}\left(\hat{X_{n}}+\mu hA^{(1)}H^{(0)}\right)
\end{eqnarray*}

\end_inset

By the derivation in the appendix, we receive the equation
\end_layout

\begin_layout Standard

\size tiny
\begin_inset Formula 
\begin{eqnarray*}
S=E\left[\frac{U_{n+1}^{2}}{U_{n}^{2}}\right] & = & \{1+\mu ht\left(\alpha\cdot\left[\left(I-\mu\Delta tA^{(0)}-\mu\sigma I_{(1,0)}A^{(1)}B^{(0)}\left(I-\sigma\sqrt{h}B^{(1)}\right)^{-1}\right)^{-1}\left(I+\sigma\frac{I_{(1,0)}}{h}B^{(0)}\left(I-\sigma\sqrt{h}B^{(1)}\right)^{-1}\right)\right]\right)\\
 &  & +\sigma I_{(1)}\left(\beta^{(1)}\cdot\left[\left(I-\sigma\sqrt{h}B^{(1)}-\mu hA^{(1)}\left(I-\mu hA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{h}B^{(0)}\right)^{-1}\left(I+\mu hA^{(1)}\left(I-\mu hA^{(0)}\right)^{-1}\right)\right]\right)\\
 &  & +\sigma\frac{I_{(1,1)}}{\sqrt{h}}\left(\beta^{(2)}\cdot\left[\left(I-\sigma\sqrt{h}B^{(1)}-\mu hA^{(1)}\left(I-\mu hA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{h}B^{(0)}\right)^{-1}\left(I+\mu hA^{(1)}\left(I-\mu hA^{(0)}\right)^{-1}\right)\right]\right)\\
 &  & +\sigma\frac{I_{(1,0)}}{h}\left(\beta^{(3)}\cdot\left[\left(I-\sigma\sqrt{h}B^{(1)}-\mu hA^{(1)}\left(I-\mu hA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{h}B^{(0)}\right)^{-1}\left(I+\mu hA^{(1)}\left(I-\mu hA^{(0)}\right)^{-1}\right)\right]\right)\\
 &  & +\sigma\frac{I_{(1,1,1)}}{h}\left(\beta^{(4)}\cdot\left[\left(I-\sigma\sqrt{h}B^{(1)}-\mu hA^{(1)}\left(I-\mu hA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{h}B^{(0)}\right)^{-1}\left(I+\mu hA^{(1)}\left(I-\mu hA^{(0)}\right)^{-1}\right)\right]\right)\}^{2}
\end{eqnarray*}

\end_inset


\size default
We apply the substitutions from the Appendix and let
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
z & =\mu h,\\
w & =\sigma\sqrt{h}.
\end{align*}

\end_inset

In this space, 
\begin_inset Formula $z$
\end_inset

 is the stability variable for the drift term and 
\begin_inset Formula $w$
\end_inset

 is the stability in the diffusion term.
 Under this scaling 
\begin_inset Formula $\left(h,\sqrt{h}\right)$
\end_inset

, the equation becomes independent of 
\begin_inset Formula $h$
\end_inset

 and thus becomes a function 
\begin_inset Formula $S(z,w)$
\end_inset

 on the coefficients of the SRK method.
 The equation 
\begin_inset Formula $S(z,w)$
\end_inset

 in terms of its coefficients for explicit methods (
\begin_inset Formula $A^{(i)}$
\end_inset

 and 
\begin_inset Formula $B^{(i)}$
\end_inset

 lower diagonal) has millions of terms and is shown in the supplemental
 Mathematica notebook.
 Determination of the stability equation for the implicit methods was found
 to be computationally intractable and is an avenue for further research.
\end_layout

\begin_layout Subsection
An Optimization Problem for Determination of Coefficients
\end_layout

\begin_layout Standard
We wish to determine the coefficients for the additive and diagonal SRK
 methods which optimize the stability.
 To do so, we generate an optimization problem which we can numerically
 solve for the coefficients.
 To simplify the problem, we let 
\begin_inset Formula $z,w\in\mathbb{R}$
\end_inset

.
 Define the function
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
f\left(z,w;N,M\right)=\int_{-M}^{M}\int_{-N}^{1}\chi_{S(z,w)\leq1}(z,w)dzdw.
\]

\end_inset

Notice that for 
\begin_inset Formula $N,M\rightarrow\infty$
\end_inset

, 
\begin_inset Formula $f$
\end_inset

 is the area of the stability region.
 Thus we define the stability-optimized diagonal SRK method as the set of
 coefficients which achieves
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\max_{A^{(i)},B^{(i)},\beta^{(i)},\alpha} & f(z,w)\\
\text{subject to: } & \text{Order Constraints}
\end{align*}

\end_inset

 However, like with the SRK methods for additive noise, we impose a few
 extra constraints to add robustness to the error estimator.
 In all cases we impose 
\begin_inset Formula $0<c_{i}^{(0)},c_{i}^{(1)}<1$
\end_inset

 .
 Additionally we can prescribe 
\begin_inset Formula $c_{4}^{(0)}=c_{4}^{(1)}=1$
\end_inset

 which we call the End-C Constraint.
 Lastly, we can prescribe the ordering constraint 
\begin_inset Formula $c_{1}^{(j)}<c_{2}^{(j)}<c_{3}^{(j)}<c_{4}^{(j)}$
\end_inset

 which we denote as the Inequality-C Constraint.
 
\end_layout

\begin_layout Standard
The resulting problem is a nonlinear programming problem with 44 variables
 and 42-48 constraint equations.
 The objective function is the two-dimensional integral of a discontinuous
 function which is determined by a polynomial of in 
\begin_inset Formula $z$
\end_inset

 and 
\begin_inset Formula $w$
\end_inset

 with approximately 3 million coefficients.
 To numerically approximate this function, we calculated the characteristic
 function on a grid with even spacing 
\begin_inset Formula $dx$
\end_inset

 using a CUDA kernel and found numerical solutions to the optimization problem
 using the JuMP framework with the NLopt backend.
 A mixed approach using many solutions of the semi-local optimizer LN_AUGLAG_EQ
 and fewer solutions from the global optimizer GN_ISRES were used to approximate
 the optimality of solutions.
 Optimization was run many times in parallel until many results produced
 methods with similar optimiality, indicating that we were likely obtained
 values near the true minimum.
\end_layout

\begin_layout Standard
The parameters 
\begin_inset Formula $N$
\end_inset

 and 
\begin_inset Formula $M$
\end_inset

 are the bounds on the stability region, but also represent a tradeoff between
 the stability in the drift and the stability in the diffusion.
 A method which is optimized when 
\begin_inset Formula $M$
\end_inset

 is small would be highly stable in the case of small noise, but would not
 be guaranteed to have good stability properties in the presence of large
 noise.
 Thus these parameters are knobs for tuning the algorithms for specific
 situations, and thus we solved the problem for different combinations of
 
\begin_inset Formula $N$
\end_inset

 and 
\begin_inset Formula $M$
\end_inset

 to determine different algorithms for the different cases.
\end_layout

\begin_layout Subsection
Resulting Approximately-Optimal Methods
\end_layout

\begin_layout Standard
The coefficients generated for approximately-optimal methods fall into three
 categories.
 In one category we have the drift-dominated stability methods where large
 
\begin_inset Formula $N$
\end_inset

 and small 
\begin_inset Formula $M$
\end_inset

 was optimized.
 On the other end we have the diffusion-dominated stability methods where
 large 
\begin_inset Formula $M$
\end_inset

 and small 
\begin_inset Formula $N$
\end_inset

 was optimized.
 Then we have the mixed stability methods which used some mixed size choices
 for 
\begin_inset Formula $N$
\end_inset

 and 
\begin_inset Formula $M$
\end_inset

.
 As a baseline, we optimized the objective without constraints on the 
\begin_inset Formula $c_{i}$
\end_inset

 to see what the 
\begin_inset Quotes eld
\end_inset

best possible method
\begin_inset Quotes erd
\end_inset

 would be.
 When this was done with large 
\begin_inset Formula $N$
\end_inset

 and 
\begin_inset Formula $M$
\end_inset

, the resulting method, which we name SRIOpt1, has almost every value of
 
\begin_inset Formula $c$
\end_inset

 satisfy the constraints, but with 
\begin_inset Formula $c_{2}^{(0)}\approx-0.04$
\end_inset

 and 
\begin_inset Formula $c_{4}^{(0)}\approx3.75$
\end_inset

.
 To see if we could produce methods which were more diffusion-stable, we
 decreased 
\begin_inset Formula $N$
\end_inset

 to optimize more in 
\begin_inset Formula $w$
\end_inset

 but failed to produce methods with substantially enlarged diffusion-stability
 over SRIOpt1.
\end_layout

\begin_layout Standard
Adding only the inequality constraints on the 
\begin_inset Formula $c_{i}$
\end_inset

 and looking for methods for drift-dominated stability, we failed to produce
 methods whose 
\begin_inset Formula $c_{i}$
\end_inset

 estimators adequately covered the interval.
 Some of the results did produce stability regions simliar to SRIOpt1 but
 with 
\begin_inset Formula $c_{i}^{(0)}<0.5$
\end_inset

 which indicates the method could have problems with error estimation.
 When placing the equality constraints on the edge 
\begin_inset Formula $c_{i}$
\end_inset

, one method, which we label SRIOpt2, resulted in similar stability to SRIOpt1
 but satisfy the 
\begin_inset Formula $c_{i}$
\end_inset

 constraints.
 In addition, this method satisfies 
\begin_inset Formula $c_{3}^{(0)}=c_{4}^{(0)}=1$
\end_inset

 and 
\begin_inset Formula $c_{3}^{(1)}=c_{4}^{(1)}=1$
\end_inset

, a property whose use will be explained in Section X.
 
\end_layout

\begin_layout Standard
To look for more diffusion-stable methods, we dropped to 
\begin_inset Formula $N=6$
\end_inset

 to encourage the methods to expand the stability in the 
\begin_inset Formula $w$
\end_inset

-plane.
 However, we could not find a method whose stability region went substantially
 beyond 
\begin_inset Formula $\left[-2,2\right]$
\end_inset

 in 
\begin_inset Formula $w$
\end_inset

.
 This was further decreased to 
\begin_inset Formula $N=1$
\end_inset

 where methods still could not go substantially beyond 
\begin_inset Formula $\left|2\right|$
\end_inset

.
 Thus we were not able to obtain methods optimized for the diffusion-dominated
 case.
 This hard barrier was hit under many different constraint and objective
 setups and under thousands of optimization runs, indicating there might
 be a diffusion-stability barrier for explicit methods.
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename C:/Users/Chris/.julia/v0.6/SRKGenerator/assets/solution_examples/DiagonalStability.pdf

\end_inset


\end_layout

\begin_layout Subsection
Approximately-Optimal Methods with Stability Detection and Switching Behaviors
\end_layout

\begin_layout Standard
In many real-world cases, one may not be able to clearly identify a model
 as drift-stability bound or diffusion-stability bound, or if the equation
 is stiff or non-stiff.
 In fact, many models may switch between such extremes.
 An example is a model with stochastic switching between different steady
 states.
 In this case, we have that the diffusion term 
\begin_inset Formula $f(t,X_{ss})\approx0$
\end_inset

 in the area of many stochastic steady states, meaning that while straddling
 a steady state the integration is heavily diffusion-stability dominated
 and usually non-stiff.
 However, when switching between steady states, 
\begin_inset Formula $f$
\end_inset

 can be very large and stiff, causing the integration to be heavily drift-stabil
ity dominated.
 Since these switches are random, the ability to adapt between these two
 behaviors could be key to achieving optimal performance.
 Given the tradeoff, we investigated how our methods allow for switching
 between methods which optimize for the different situations.
 
\end_layout

\begin_layout Standard
The basis for our method is a straight-forward extension of a method proposed
 for deterministic differential equations.
 The idea is to create a cheap approximation to the dominant eigenvalues
 of the Jacobians for the drift and diffusion terms.
 If 
\begin_inset Formula $v$
\end_inset

 is the eigenvector of the respective Jacobian, then for 
\begin_inset Formula $\Vert v\Vert$
\end_inset

 sufficiently small,
\begin_inset Formula 
\[
\left|\lambda_{D}\right|\approx\frac{\Vert f(t,x+v)-f(t,x)\Vert}{\Vert v\Vert},\thinspace\thinspace\thinspace\left|\lambda_{N}\right|\approx\frac{\Vert g(t,x+v)-g(t,x)\Vert}{\Vert v\Vert}
\]

\end_inset

 where 
\begin_inset Formula $\left|\lambda_{D}\right|$
\end_inset

 and 
\begin_inset Formula $\left|\lambda_{N}\right|$
\end_inset

 are the estimates of the dominant eigenvalues for the deterministic and
 noise functions respectively.
 We have in approximation that 
\begin_inset Formula $H_{i}^{(k)}$
\end_inset

 is an approximation for 
\begin_inset Formula $X_{t+c_{i}^{(k)}h}$
\end_inset

 and thus the difference between two successive approximations at the same
 timepoint, 
\begin_inset Formula $c_{i}^{(k)}=c_{j}^{(k)}$
\end_inset

, then the following serves as a local Jacobian estimate:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\left|\lambda_{D}\right|\approx\frac{\Vert f(t+c_{i}^{(0)}h,H_{i}^{(0)})-f(t+c_{j}^{(0)}h,H_{j}^{(0)})\Vert}{\Vert H_{i}^{(0)}-H_{j}^{(0)}\Vert},\thinspace\thinspace\thinspace\left|\lambda_{N}\right|\approx\frac{\Vert f(t+c_{i}^{(1)}h,H_{i}^{(1)})-f(t+c_{j}^{(1)}h,H_{j}^{(1)})\Vert}{\Vert H_{i}^{(1)}-H_{j}^{(1)}\Vert}
\]

\end_inset

 If we had already computed a successful step, we would like to know if
 in the next calculation we should switch methods due to stability.
 Thus it makes sense to approximate the Jacobian at the end of the interval,
 meaning 
\begin_inset Formula $i=s$
\end_inset

 and 
\begin_inset Formula $j=s-1$
\end_inset

 where 
\begin_inset Formula $s$
\end_inset

 is the number of stages.
 Then if 
\begin_inset Formula $z_{min}$
\end_inset

 is the minimum 
\begin_inset Formula $z\in\mathbb{R}$
\end_inset

 such that 
\begin_inset Formula $z$
\end_inset

 is in the stability region for the method, 
\begin_inset Formula $\frac{h\left|\lambda_{D}\right|}{z_{min}}>1$
\end_inset

 when the steps are outside the stability region.
 Because the drift and mixed stability methods do not track the noise axis
 directly, we instead modify 
\begin_inset Formula $w_{min}$
\end_inset

 to be 
\begin_inset Formula $\frac{2}{3}$
\end_inset

 of the maximum of the stability region in the noise axis.
 
\end_layout

\begin_layout Standard
Hairer noted that, for ODEs, if a RK method has 
\begin_inset Formula $c_{i}=c_{j}=1$
\end_inset

, then it follows that
\begin_inset Formula 
\[
\rho=\frac{\Vert k_{i}-k_{j}\Vert}{\Vert g_{i}-g_{j}\Vert}
\]

\end_inset

 where 
\begin_inset Formula $k_{i}=f(t+c_{i}h,g_{i})$
\end_inset

 is an estimate of the eigenvalues for the Jacobian of 
\begin_inset Formula $f$
\end_inset

.
 Given the construction of SRIOpt2, a natural extension is 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\left|\lambda_{D}\right|\approx\frac{\Vert f\left(t_{n}+c_{4}^{(0)}h,H_{4}^{(0)}\right)-f\left(t_{n}+c_{3}^{(0)}h,H_{3}^{(0)}\right)\Vert}{\Vert H_{4}^{(0)}-H_{3}^{(0)}\Vert},\thinspace\thinspace\thinspace\left|\lambda_{N}\right|\approx\frac{\Vert g\left(t_{n}+c_{4}^{(0)}h,H_{4}^{(1)}\right)-g\left(t_{n}+c_{3}^{(0)}h,H_{3}^{(1)}\right)\Vert}{\Vert H_{4}^{(1)}-H_{3}^{(1)}\Vert}
\]

\end_inset

Given that these values are all part of the actual step calculations, this
 stiffness estimate is free.
 By comparing these values to the stability plot in Figure X, we use the
 following heristic to decide if SRIOpt2 is stability-bound in its steps:
 
\end_layout

\begin_layout Enumerate
If 
\begin_inset Formula $10>\left|\lambda_{D}\right|>2.5$
\end_inset

, then we check if 
\begin_inset Formula $h\left|\lambda_{N}\right|>1$
\end_inset

.
\end_layout

\begin_layout Enumerate
If 
\begin_inset Formula $\left|\lambda_{D}\right|<2.5$
\end_inset

, then we check if 
\begin_inset Formula $h\left|\lambda_{N}\right|/2>1$
\end_inset

.
\end_layout

\begin_layout Standard
The denominator is chosen as a reasonable approximation to the edge of the
 stability region.
 If either of those conditions are satisfied, then 
\begin_inset Formula $h$
\end_inset

 is constrained by the stability region.
 The solver can thus alert the user that the method is non-stiff or use
 this estimate to switch to a method more suitable for stiff equations.
 In addition, the error estimator gives separate error estimates in the
 drift and diffusion terms.
 A scheme could combine these two facts to develop a more robust stiffness
 detection method, and label the stiffness as either drift or diffusion
 dominated.
\end_layout

\begin_layout Standard
We end by noting that SRSRA2 has the same property, allowing stiffness detection
 via
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\left|\lambda_{D}\right|\approx\frac{\Vert f\left(t_{n}+c_{3}^{(0)}h,H_{3}^{(0)}\right)-f\left(t_{n}+c_{2}^{(0)}h,H_{2}^{(0)}\right)\Vert}{\Vert H_{3}^{(0)}-H_{2}^{(0)}\Vert}
\]

\end_inset

 and, employing a similar method as the deterministic case, check for stiffness
 via the estimate 
\begin_inset Formula $h\left|\lambda_{D}\right|/5>1$
\end_inset

.
\end_layout

\begin_layout Section
Numerical Results
\end_layout

\begin_layout Subsection
SOSRA Numerical Experiments
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename C:/Users/Chris/.julia/v0.6/SRKGenerator/assets/paper_figures/SRA_efficiency.pdf
	scale 50

\end_inset


\end_layout

\begin_layout Subsection
SOSRI Numerical Experiments
\end_layout

\begin_layout Itemize
Efficiency on Oval2 problem?
\end_layout

\begin_layout Section
Discussion
\end_layout

\begin_layout Itemize
non-commutative and commutative
\end_layout

\begin_layout Itemize
principle truncation
\end_layout

\begin_layout Section
Appendix: Derivations
\end_layout

\begin_layout Standard

\size tiny
\begin_inset Formula 
\begin{eqnarray*}
\left(I-\mu\Delta tA^{(0)}\right)H^{(0)} & = & U_{n}+\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)^{-1}\left(U_{n}+\mu\Delta tA^{(1)}H^{(0)}\right),\\
\left(I-\mu\Delta tA^{(0)}\right)H^{(0)}-\left[\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)^{-1}\right]\mu\Delta tA^{(1)}H^{(0)} & = & U_{n}+\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)^{-1}U_{n}\\
\left(I-\mu\Delta tA^{(0)}-\mu\Delta tA^{(1)}\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)^{-1}\right)H^{(0)} & = & \left(I+\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)^{-1}\right)U_{n}\\
H^{(0)} & = & \left(I-\mu\Delta tA^{(0)}-\mu\sigma I_{(1,0)}A^{(1)}B^{(0)}\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)^{-1}\right)^{-1}\left(I+\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)^{-1}\right)U_{n}
\end{eqnarray*}

\end_inset


\begin_inset Formula 
\begin{eqnarray*}
\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)H^{(1)} & = & U_{n}+\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\left(U_{n}+\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}H^{(1)}\right)\\
\left(I-\sigma\sqrt{\Delta t}B^{(1)}-\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\right)H^{(1)} & = & U_{n}+\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}U_{n}\\
\left(I-\sigma\sqrt{\Delta t}B^{(1)}-\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\right)H^{(1)} & = & \left(I+\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\right)U_{n}\\
H^{(1)} & = & \left(I-\sigma\sqrt{\Delta t}B^{(1)}-\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\right)^{-1}\left(I+\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\right)U_{n}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard

\size tiny
\begin_inset Formula 
\begin{eqnarray*}
U_{n+1} & = & U_{n}+\mu\Delta t\left(\alpha\cdot\left[\left(I-\mu\Delta tA^{(0)}-\mu\sigma I_{(1,0)}A^{(1)}B^{(0)}\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)^{-1}\right)^{-1}\left(I+\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\left(I-\sigma\sqrt{\Delta t}B^{(1)}\right)^{-1}\right)\right]U_{n}\right)\\
 &  & +\sigma I_{(1)}\left(\beta^{(1)}\cdot\left[\left(I-\sigma\sqrt{\Delta t}B^{(1)}-\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\right)^{-1}\left(I+\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\right)\right]U_{n}\right)\\
 &  & +\sigma\frac{I_{(1,1)}}{\sqrt{\Delta t}}\left(\beta^{(2)}\cdot\left[\left(I-\sigma\sqrt{\Delta t}B^{(1)}-\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\right)^{-1}\left(I+\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\right)\right]U_{n}\right)\\
 &  & +\sigma\frac{I_{(1,0)}}{\Delta t}\left(\beta^{(3)}\cdot\left[\left(I-\sigma\sqrt{\Delta t}B^{(1)}-\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\right)^{-1}\left(I+\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\right)\right]U_{n}\right)\\
 &  & +\sigma\frac{I_{(1,1,1)}}{\Delta t}\left(\beta^{(4)}\cdot\left[\left(I-\sigma\sqrt{\Delta t}B^{(1)}-\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\sigma\frac{I_{(1,0)}}{\Delta t}B^{(0)}\right)^{-1}\left(I+\mu\Delta tA^{(1)}\left(I-\mu\Delta tA^{(0)}\right)^{-1}\right)\right]U_{n}\right)
\end{eqnarray*}

\end_inset


\size default
 Thus we substitute in the Wiktorsson approximations
\begin_inset Formula 
\begin{align*}
I_{(1,1)} & =\frac{1}{2}\left(\Delta W^{2}-h\right)\\
I_{(1,1,1)} & =\frac{1}{6}\left(\Delta W^{3}-3h\Delta W\right)\\
I_{(1.0)} & =\frac{1}{2}h\left(\Delta W+\frac{1}{\sqrt{3}}\Delta Z\right)
\end{align*}

\end_inset

 where 
\begin_inset Formula $\Delta Z\sim N(0,h)$
\end_inset

 is independent of 
\begin_inset Formula $\Delta W\sim N(0,h)$
\end_inset

.
 By the properties of the normal distribution, we have that
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E\left[\left(\Delta W\right)^{n}\right]=0
\]

\end_inset

 for any odd 
\begin_inset Formula $n$
\end_inset

 and
\begin_inset Formula 
\begin{eqnarray*}
E\left[\left(\Delta W\right)^{2}\right] & = & h\\
E\left[\left(\Delta W\right)^{4}\right] & = & 3h^{2}\\
E\left[\left(\Delta W\right)^{6}\right] & = & 15h^{3}\\
E\left[\left(\Delta W\right)^{8}\right] & = & 105h^{4}.
\end{eqnarray*}

\end_inset


\end_layout

\end_body
\end_document
